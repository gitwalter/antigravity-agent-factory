#!/usr/bin/env python3
"""
Pre-Commit Runner

Generated by Cursor Agent Factory

Runs validation scripts before commit. Supports parallel execution and
automatic file staging after fixes.

Usage:
    python scripts/git/pre_commit_runner.py --check
    python scripts/git/pre_commit_runner.py --sync
    python scripts/git/pre_commit_runner.py --fast
"""

import argparse
import subprocess
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional


@dataclass
class ScriptResult:
    """Result of running a validation script."""

    script_path: Path
    success: bool
    output: str
    error: Optional[str] = None
    exit_code: int = 0


@dataclass
class PreCommitReport:
    """Report of pre-commit validation run."""

    total_scripts: int
    successful: int
    failed: int
    results: List[ScriptResult]


class PreCommitRunner:
    """
    Runs pre-commit validation scripts.

    Discovers scripts in scripts/validation/ and scripts/docs/ directories
    and executes them with appropriate flags.
    """

    def __init__(
        self, root_dir: Path, sync_mode: bool = False, fast_mode: bool = False
    ):
        """
        Initialize runner.

        Args:
            root_dir: Project root directory
            sync_mode: If True, run scripts in sync mode (apply fixes)
            fast_mode: If True, skip slow checks
        """
        self.root_dir = root_dir.resolve()
        self.sync_mode = sync_mode
        self.fast_mode = fast_mode

    def discover_scripts(self) -> List[Path]:
        """
        Discover validation scripts in scripts directories.

        Returns:
            List of script paths
        """
        scripts = []

        # Look in scripts/validation/ and scripts/docs/
        for scripts_dir_name in ["validation", "docs"]:
            scripts_dir = self.root_dir / "scripts" / scripts_dir_name
            if scripts_dir.exists():
                # Find Python scripts
                for script_path in scripts_dir.glob("*.py"):
                    if script_path.name != "__init__.py":
                        scripts.append(script_path)

        return sorted(scripts)

    def run_script(self, script_path: Path) -> ScriptResult:
        """
        Run a single validation script.

        Args:
            script_path: Path to script

        Returns:
            ScriptResult object
        """

        script_name = script_path.name
        cmd = [sys.executable, str(script_path)]

        # Script-specific argument mapping
        if self.sync_mode:
            # Sync/Update Mode
            if script_name == "validate_json_syntax.py":
                cmd.append("--all")
            elif script_name == "update_index.py":
                cmd.append("--full")
            elif script_name in [
                "sync_manifest_versions.py",
                "sync_test_counts.py",
                "sync_knowledge_counts.py",
                "sync_artifacts.py",
            ]:
                cmd.append("--sync")
            elif script_name == "validate_readme_structure.py":
                cmd.append("--update")
            elif script_name == "fix_values.py":
                cmd.append("--update")
            elif script_name == "changelog_helper.py":
                cmd.append("--check")
            else:
                # Default for others (no args or custom)
                pass
        else:
            # Check Mode
            if script_name == "validate_json_syntax.py":
                cmd.append("--all")
            elif script_name == "update_index.py":
                cmd.append("--check")
            elif script_name == "validate_readme_structure.py":
                cmd.append("--check")
            elif script_name == "fix_values.py":
                cmd.append("--check")
            elif script_name == "changelog_helper.py":
                cmd.append("--check")
            else:
                # Default for others
                pass

        if self.fast_mode and script_name == "sync_artifacts.py":
            cmd.append("--fast")

        try:
            result = subprocess.run(
                cmd,
                cwd=self.root_dir,
                capture_output=True,
                text=True,
                encoding="utf-8",  # Force UTF-8 for subprocess output
                errors="replace",  # Replace invalid characters
                timeout=300,  # 5 minute timeout
            )

            return ScriptResult(
                script_path=script_path,
                success=result.returncode == 0,
                output=result.stdout,
                error=result.stderr if result.returncode != 0 else None,
                exit_code=result.returncode,
            )
        except subprocess.TimeoutExpired:
            return ScriptResult(
                script_path=script_path,
                success=False,
                output="",
                error="Script timed out after 5 minutes",
                exit_code=124,
            )
        except Exception as e:
            return ScriptResult(
                script_path=script_path,
                success=False,
                output="",
                error=str(e),
                exit_code=1,
            )

    def run_scripts(self, max_workers: int = 4) -> PreCommitReport:
        """
        Run all discovered scripts (optionally in parallel).

        Args:
            max_workers: Maximum parallel workers

        Returns:
            PreCommitReport object
        """
        scripts = self.discover_scripts()

        if not scripts:
            return PreCommitReport(total_scripts=0, successful=0, failed=0, results=[])

        results: List[ScriptResult] = []

        # Run scripts in parallel
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_script = {
                executor.submit(self.run_script, script): script for script in scripts
            }

            for future in as_completed(future_to_script):
                result = future.result()
                results.append(result)

        successful = sum(1 for r in results if r.success)
        failed = len(results) - successful

        return PreCommitReport(
            total_scripts=len(scripts),
            successful=successful,
            failed=failed,
            results=results,
        )

    def validate_json(self) -> bool:
        """
        Quick JSON validation for common JSON files.

        Returns:
            True if all JSON files are valid
        """
        json_files = [
            self.root_dir / "package.json",
            self.root_dir / "tsconfig.json",
            self.root_dir / "pyproject.toml",  # Not JSON but common
        ]

        import json

        for json_file in json_files:
            if json_file.exists() and json_file.suffix == ".json":
                try:
                    json_file.read_text(encoding="utf-8")
                    json.loads(json_file.read_text(encoding="utf-8"))
                except json.JSONDecodeError as e:
                    print(f"âŒ Invalid JSON in {json_file}: {e}")
                    return False

        return True

    def auto_stage(self) -> bool:
        """
        Auto-stage files that were modified by sync scripts.

        Returns:
            True if staging succeeded
        """
        try:
            result = subprocess.run(
                ["git", "add", "-u"], cwd=self.root_dir, capture_output=True, text=True
            )
            return result.returncode == 0
        except Exception:
            return False


def main():
    """Main entry point."""
    if sys.platform == "win32":
        sys.stdout.reconfigure(encoding="utf-8")

    parser = argparse.ArgumentParser(description="Run pre-commit validation scripts")
    parser.add_argument(
        "--sync", action="store_true", help="Run scripts in sync mode (apply fixes)"
    )
    parser.add_argument(
        "--check", action="store_true", help="Run scripts in check mode (validate only)"
    )
    parser.add_argument("--fast", action="store_true", help="Skip slow checks")
    parser.add_argument(
        "--root",
        type=str,
        default=".",
        help="Project root directory (default: current directory)",
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=4,
        help="Maximum parallel workers (default: 4)",
    )

    args = parser.parse_args()

    # Default to sync mode if neither specified
    sync_mode = args.sync or (not args.check)

    root_dir = Path(args.root).resolve()
    runner = PreCommitRunner(root_dir, sync_mode=sync_mode, fast_mode=args.fast)

    # Quick JSON validation first
    if not runner.validate_json():
        print("âŒ JSON validation failed")
        return 1

    # Run scripts
    report = runner.run_scripts(max_workers=args.max_workers)

    # Print results
    print("\nğŸ“Š Pre-commit validation report:")
    print(f"   Total scripts: {report.total_scripts}")
    print(f"   Successful: {report.successful}")
    print(f"   Failed: {report.failed}")
    print()

    for result in report.results:
        if result.success:
            print(f"âœ… {result.script_path.name}")
            if result.output.strip():
                for line in result.output.strip().splitlines():
                    print(f"   {line}")
        else:
            print(f"âŒ {result.script_path.name}")
            if result.error:
                for line in result.error.strip().splitlines():
                    print(f"   {line}")
            if result.output:
                for line in result.output.strip().splitlines():
                    print(f"   {line}")

    # Auto-stage if in sync mode
    if sync_mode and report.successful > 0:
        if runner.auto_stage():
            print("\nâœ… Auto-staged modified files")

    if report.failed > 0:
        print(f"\nâŒ {report.failed} script(s) failed")
        return 1

    print("\nâœ… All pre-commit checks passed")
    return 0


if __name__ == "__main__":
    sys.exit(main())
