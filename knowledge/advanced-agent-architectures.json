{
    "metadata": {
        "name": "Advanced Agent Architectures",
        "description": "Cutting-edge agent architectures including ReAct, Reflection, Tree of Thoughts, Plan-and-Execute, BabyAGI, AutoGPT, and CAMEL-AI",
        "version": "1.0.0",
        "last_updated": "2026-02-07",
        "architectures": [
            "react",
            "reflection",
            "tot",
            "plan-execute",
            "babyagi",
            "autogpt",
            "camel"
        ]
    },
    "react_pattern": {
        "description": "Reasoning and Acting - Synergize reasoning traces and task-specific actions",
        "key_concept": "Interleave thought, action, and observation in a loop",
        "implementation": "```python\nfrom langchain.agents import create_react_agent\nfrom langchain_openai import ChatOpenAI\nfrom langchain.tools import Tool\n\nclass ReActAgent:\n    def __init__(self, tools, llm=None):\n        self.llm = llm or ChatOpenAI(model=\"gpt-4o\", temperature=0)\n        self.tools = tools\n        \n        prompt = '''Answer the following questions as best you can. You have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: {input}\nThought:{agent_scratchpad}'''\n        \n        self.agent = create_react_agent(self.llm, self.tools, prompt)\n    \n    def run(self, query):\n        return self.agent.invoke({\"input\": query})\n```",
        "benefits": ["Improved interpretability\", \"Better error recovery\", \"Dynamic tool selection\"],\n    \"use_cases\": [\"Question answering\", \"Task completion\", \"Research\"]
        },
  \"reflection_pattern\": {
    \"description\": \"Self-critique and iterative refinement through think-act-reflect loops\",\n    \"key_concept\": \"Agent evaluates its own outputs and improves them\",\n    \"implementation\": \"```python\nclass ReflectionAgent:\n    def __init__(self, llm):\n        self.llm = llm\n        self.max_iterations = 3\n    \n    async def run(self, task):\n        output = await self.generate(task)\n        \n        for i in range(self.max_iterations):\n            critique = await self.reflect(task, output)\n            \n            if critique['is_satisfactory']:\n                break\n            \n            output = await self.improve(task, output, critique['feedback'])\n        \n        return output\n    \n    async def generate(self, task):\n        response = await self.llm.ainvoke(f\"Complete this task: {task}\")\n        return response.content\n    \n    async def reflect(self, task, output):\n        critique_prompt = f'''Task: {task}\nOutput: {output}\n\nCritique this output. Is it satisfactory? What could be improved?'''\n        \n        critique = await self.llm.ainvoke(critique_prompt)\n        return {\n            'is_satisfactory': 'satisfactory' in critique.content.lower(),\n            'feedback': critique.content\n        }\n    \n    async def improve(self, task, output, feedback):\n        improve_prompt = f'''Task: {task}\nPrevious output: {output}\nFeedback: {feedback}\n\nImprove the output based on the feedback.'''\n        \n        improved = await self.llm.ainvoke(improve_prompt)\n        return improved.content\n```\",\n    \"benefits\": [\"Higher quality outputs\", \"Self-correction\", \"Reduced hallucinations\"],\n    \"use_cases\": [\"Code generation\", \"Writing\", \"Complex reasoning\"]
    },
  \"tree_of_thoughts\": {
    \"description\": \"Explore multiple reasoning paths simultaneously with evaluation and pruning\",\n    \"key_concept\": \"Generate multiple solution paths, evaluate them, and explore the most promising\",\n    \"implementation\": \"```python\nimport asyncio\nfrom typing import List, Dict\n\nclass TreeOfThoughts:\n    def __init__(self, llm, branching_factor=3, depth=3):\n        self.llm = llm\n        self.branching_factor = branching_factor\n        self.depth = depth\n    \n    async def solve(self, problem):\n        # Generate initial thoughts\n        thoughts = await self.generate_thoughts(problem, [])\n        \n        # Explore tree\n        best_path = await self.explore(problem, thoughts, depth=0)\n        \n        return best_path\n    \n    async def generate_thoughts(self, problem, current_path):\n        prompt = f'''Problem: {problem}\nCurrent reasoning path: {current_path}\n\nGenerate {self.branching_factor} different next steps or approaches.'''\n        \n        response = await self.llm.ainvoke(prompt)\n        thoughts = response.content.split('\\n\\n')[:self.branching_factor]\n        return thoughts\n    \n    async def evaluate_thought(self, problem, path):\n        eval_prompt = f'''Problem: {problem}\nReasoning path: {path}\n\nRate this reasoning path from 0-10 for likelihood of solving the problem.'''\n        \n        response = await self.llm.ainvoke(eval_prompt)\n        try:\n            score = float(response.content.strip())\n            return min(max(score, 0), 10)\n        except:\n            return 5.0\n    \n    async def explore(self, problem, thoughts, depth):\n        if depth >= self.depth:\n            # Evaluate final thoughts\n            scores = await asyncio.gather(*[\n                self.evaluate_thought(problem, thought) for thought in thoughts\n            ])\n            best_idx = scores.index(max(scores))\n            return thoughts[best_idx]\n        \n        # Expand and evaluate\n        expanded = []\n        for thought in thoughts:\n            new_thoughts = await self.generate_thoughts(problem, [thought])\n            expanded.extend([(thought, new) for new in new_thoughts])\n        \n        # Score all paths\n        scores = await asyncio.gather(*[\n            self.evaluate_thought(problem, f\"{base} -> {new}\") \n            for base, new in expanded\n        ])\n        \n        # Keep top k\n        top_k = sorted(zip(expanded, scores), key=lambda x: x[1], reverse=True)[:self.branching_factor]\n        top_thoughts = [f\"{base} -> {new}\" for (base, new), _ in top_k]\n        \n        return await self.explore(problem, top_thoughts, depth + 1)\n```\",\n    \"benefits\": [\"Explores multiple solutions\", \"Better for complex problems\", \"Finds non-obvious solutions\"],\n    \"use_cases\": [\"Mathematical reasoning\", \"Strategic planning\", \"Creative problem solving\"]
},
  \"plan_and_execute\": {
    \"description\": \"Strategic planning phase followed by execution phase\",\n    \"key_concept\": \"First create a comprehensive plan, then execute it step by step\",\n    \"implementation\": \"```python\nfrom langgraph.graph import StateGraph, END\nfrom typing import TypedDict, List\n\nclass PlanExecuteState(TypedDict):\n    input: str\n    plan: List[str]\n    past_steps: List[tuple]\n    response: str\n\nclass PlanAndExecuteAgent:\n    def __init__(self, llm, tools):\n        self.llm = llm\n        self.tools = {tool.name: tool for tool in tools}\n        self.graph = self.create_graph()\n    \n    def create_graph(self):\n        workflow = StateGraph(PlanExecuteState)\n        \n        workflow.add_node(\"planner\", self.plan_step)\n        workflow.add_node(\"executor\", self.execute_step)\n        workflow.add_node(\"replan\", self.replan_step)\n        \n        workflow.set_entry_point(\"planner\")\n        workflow.add_edge(\"planner\", \"executor\")\n        workflow.add_conditional_edges(\n            \"executor\",\n            self.should_continue,\n            {\"continue\": \"replan\", \"end\": END}\n        )\n        workflow.add_edge(\"replan\", \"executor\")\n        \n        return workflow.compile()\n    \n    async def plan_step(self, state: PlanExecuteState):\n        plan_prompt = f'''Create a step-by-step plan to accomplish: {state[\"input\"]}\n\nAvailable tools: {list(self.tools.keys())}\n\nProvide a numbered list of steps.'''\n        \n        response = await self.llm.ainvoke(plan_prompt)\n        steps = [s.strip() for s in response.content.split('\\n') if s.strip() and s[0].isdigit()]\n        \n        return {\"plan\": steps}\n    \n    async def execute_step(self, state: PlanExecuteState):\n        current_step = state[\"plan\"][len(state[\"past_steps\"])]\n        \n        exec_prompt = f'''Execute this step: {current_step}\n\nContext from previous steps: {state[\"past_steps\"]}\n\nUse available tools if needed.'''\n        \n        response = await self.llm.ainvoke(exec_prompt)\n        \n        return {\n            \"past_steps\": state[\"past_steps\"] + [(current_step, response.content)]\n        }\n    \n    def should_continue(self, state: PlanExecuteState):\n        if len(state[\"past_steps\"]) >= len(state[\"plan\"]):\n            return \"end\"\n        return \"continue\"\n    \n    async def replan_step(self, state: PlanExecuteState):\n        # Optionally adjust plan based on execution results\n        return state\n```\",\n    \"benefits\": [\"Clear structure\", \"Better for complex tasks\", \"Easier debugging\"],\n    \"use_cases\": [\"Multi-step workflows\", \"Project planning\", \"Research tasks\"]
},
  \"babyagi\": {
    \"description\": \"Autonomous task queue system with creation, prioritization, and execution\",\n    \"key_concept\": \"Agent creates tasks, prioritizes them, and executes autonomously\",\n    \"implementation\": \"```python\nimport asyncio\nfrom collections import deque\n\nclass BabyAGI:\n    def __init__(self, llm, objective):\n        self.llm = llm\n        self.objective = objective\n        self.task_queue = deque()\n        self.completed_tasks = []\n    \n    async def run(self, initial_task=\"Develop a task list\"):\n        self.task_queue.append({\"id\": 1, \"task\": initial_task})\n        task_id_counter = 1\n        \n        while self.task_queue:\n            # Get next task\n            task = self.task_queue.popleft()\n            \n            # Execute task\n            result = await self.execute_task(task)\n            self.completed_tasks.append({**task, \"result\": result})\n            \n            # Create new tasks\n            new_tasks = await self.create_tasks(task, result)\n            \n            # Prioritize and add to queue\n            prioritized = await self.prioritize_tasks(new_tasks)\n            \n            for new_task in prioritized:\n                task_id_counter += 1\n                self.task_queue.append({\"id\": task_id_counter, **new_task})\n    \n    async def execute_task(self, task):\n        context = self.get_context()\n        prompt = f'''Objective: {self.objective}\nTask: {task[\"task\"]}\nContext: {context}\n\nExecute this task and provide results.'''\n        \n        response = await self.llm.ainvoke(prompt)\n        return response.content\n    \n    async def create_tasks(self, completed_task, result):\n        prompt = f'''Objective: {self.objective}\nCompleted task: {completed_task[\"task\"]}\nResult: {result}\n\nBased on this, create new tasks needed to achieve the objective. Return as numbered list.'''\n        \n        response = await self.llm.ainvoke(prompt)\n        tasks = [s.strip() for s in response.content.split('\\n') if s.strip() and s[0].isdigit()]\n        return [{\"task\": t} for t in tasks]\n    \n    async def prioritize_tasks(self, tasks):\n        if not tasks:\n            return []\n        \n        prompt = f'''Objective: {self.objective}\nTasks to prioritize: {tasks}\n\nPrioritize these tasks. Return in priority order.'''\n        \n        response = await self.llm.ainvoke(prompt)\n        # Parse and return prioritized tasks\n        return tasks  # Simplified\n    \n    def get_context(self):\n        return \"\\n\".join([f\"{t['task']}: {t['result']}\" for t in self.completed_tasks[-5:]])\n```\",\n    \"benefits\": [\"Autonomous operation\", \"Dynamic task creation\", \"Self-organizing\"],\n    \"use_cases\": [\"Research projects\", \"Content creation\", \"Data analysis\"]
},
  \"autogpt\": {
    \"description\": \"Autonomous agent with goal breakdown and independent execution\",\n    \"key_concept\": \"Agent breaks down goals and executes them independently with minimal human intervention\",\n    \"components\": [\"Goal setting\", \"Task breakdown\", \"Tool use\", \"Memory\", \"Self-evaluation\"],\n    \"best_practices\": [\n      \"Set clear objectives and constraints\",\n      \"Implement resource limits (API calls, time)\",\n      \"Use memory for context retention\",\n      \"Implement safety checks\",\n      \"Log all actions for audit\"\n    ]
},
  \"camel_ai\": {
    \"description\": \"Structured role-play framework with multi-agent pipelines and RAG\",\n    \"key_concept\": \"Agents take on specific roles and collaborate through structured communication\",\n    \"implementation\": \"```python\nfrom camel.agents import ChatAgent\nfrom camel.messages import BaseMessage\nfrom camel.societies import RolePlaying\n\nclass CAMELSystem:\n    def __init__(self, task_prompt):\n        self.task_prompt = task_prompt\n    \n    def run_role_play(self, assistant_role, user_role, num_turns=10):\n        role_play_session = RolePlaying(\n            assistant_role_name=assistant_role,\n            user_role_name=user_role,\n            task_prompt=self.task_prompt\n        )\n        \n        # Initialize\n        assistant_msg, user_msg = role_play_session.init_chat()\n        \n        # Run conversation\n        for turn in range(num_turns):\n            assistant_response = role_play_session.step(user_msg)\n            user_response = role_play_session.step(assistant_msg)\n            \n            if role_play_session.is_terminated():\n                break\n        \n        return role_play_session.get_chat_history()\n```\",\n    \"use_cases\": [\"Collaborative problem solving\", \"Debate simulation\", \"Creative writing\"]
},
  \"verifier_models\": {
    \"description\": \"Models trained to verify logic and outputs of other models\",\n    \"key_concept\": \"Separate model checks the reasoning and outputs for correctness\",\n    \"implementation\": \"```python\nclass VerifierAgent:\n    def __init__(self, generator_llm, verifier_llm):\n        self.generator = generator_llm\n        self.verifier = verifier_llm\n    \n    async def generate_and_verify(self, problem, num_attempts=3):\n        for attempt in range(num_attempts):\n            # Generate solution\n            solution = await self.generator.ainvoke(f\"Solve: {problem}\")\n            \n            # Verify solution\n            verification = await self.verifier.ainvoke(\n                f\"Problem: {problem}\\nSolution: {solution.content}\\n\\nVerify this solution. Is it correct?\"\n            )\n            \n            if \"correct\" in verification.content.lower():\n                return solution.content\n        \n        return \"Could not generate verified solution\"\n```\",\n    \"use_cases\": [\"Mathematical reasoning\", \"Code generation\", \"High-stakes decisions\"]
},
  \"context_graphs\": {
    \"description\": \"Graph-based context management for long-horizon tasks\",\n    \"key_concept\": \"Represent task context as a graph to guide agent through complex workflows\",\n    \"benefits\": [\"Better long-term planning\", \"Context retention\", \"Non-linear workflows\"]
},
  \"best_practices\": [\n    \"Choose architecture based on task complexity\",\n    \"Implement proper error handling and recovery\",\n    \"Use logging and tracing for debugging\",\n    \"Set resource limits (time, tokens, API calls)\",\n    \"Implement human-in-the-loop for critical decisions\",\n    \"Test extensively before production deployment\",\n    \"Monitor agent behavior and costs\",\n    \"Implement safety guardrails\"\n  ],\n  \"resources\": [\n    \"https://arxiv.org/abs/2210.03629\",\n    \"https://arxiv.org/abs/2303.11366\",\n    \"https://github.com/yoheinakajima/babyagi\",\n    \"https://github.com/Significant-Gravitas/AutoGPT\",\n    \"https://github.com/camel-ai/camel\"\n  ]\n}