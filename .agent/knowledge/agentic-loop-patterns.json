{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "id": "agentic-loop-patterns",
  "title": "Agentic Loop Patterns",
  "name": "Agentic Loop Patterns",
  "description": "Core patterns for building agentic loops including ReAct, reflection, planning, and iterative refinement patterns",
  "version": "1.0.0",
  "category": "agent-patterns",
  "axiomAlignment": {
    "A1_verifiability": "All reasoning steps and tool calls are logged for verification",
    "A2_user_primacy": "Confirms before consequential actions; user goals drive loop termination",
    "A3_transparency": "Reasoning process is explicit and traceable through thought-action-observation",
    "A4_non_harm": "Validates tool inputs and outputs; error recovery prevents harmful cascades",
    "A5_consistency": "Maintains consistent reasoning patterns and termination conditions across loops"
  },
  "related_skills": [
    "langchain-usage",
    "langgraph-agent-building",
    "tool-usage",
    "anthropic-patterns",
    "memory-management",
    "agentic-loops"
  ],
  "related_knowledge": [
    "langchain-patterns.json",
    "langgraph-workflows.json",
    "multi-agent-coordination.json",
    "error-handling-patterns.json"
  ],
  "patterns": {
    "react_pattern": {
      "description": "Reasoning and Acting pattern - alternates between reasoning and tool execution",
      "structure": {
        "steps": [
          "Thought: Reason about what to do",
          "Action: Select appropriate tool",
          "Action Input: Provide input to tool",
          "Observation: Analyze tool output",
          "Repeat until sufficient information",
          "Final Answer: Provide response"
        ]
      },
      "implementation": {
        "framework": "langchain.agents.create_react_agent",
        "components": [
          "ChatModel",
          "Tools",
          "Prompt",
          "AgentExecutor"
        ],
        "example": "from langchain.agents import create_react_agent, AgentExecutor\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\n\n@tool\ndef get_weather(location: str) -> str:\n    '''Get the current weather for a location.'''\n    return f'Weather in {location}: Sunny, 72\u00b0F'\n\ntools = [get_weather]\nllm = ChatOpenAI(model='gpt-4', temperature=0)\nagent = create_react_agent(llm, tools, prompt)\nexecutor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=15)"
      },
      "use_when": "Agent needs to reason about actions step-by-step; Multi-step problem solving; Tool-based workflows; Transparent reasoning required",
      "best_practices": [
        "Keep tool descriptions clear and specific",
        "Use structured outputs for consistent parsing",
        "Implement proper error handling for tool failures",
        "Add observability with LangSmith tracing",
        "Set max_iterations to prevent infinite loops",
        "Log reasoning steps for transparency"
      ],
      "axiom_alignment": {
        "A1": "Verifiability - All reasoning steps and tool calls are logged",
        "A2": "User Primacy - Confirms before consequential actions",
        "A3": "Transparency - Reasoning process is explicit and traceable",
        "A4": "Non-Harm - Validates tool inputs and outputs",
        "A5": "Consistency - Maintains consistent reasoning patterns"
      },
      "code_example": "from langchain.agents import create_react_agent, AgentExecutor\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\n\n@tool\ndef get_weather(location: str) -> str:\n    '''Get the current weather for a location.'''\n    return f'Weather in {location}: Sunny, 72\u00b0F'\n\ntools = [get_weather]\nllm = ChatOpenAI(model='gpt-4', temperature=0)\nagent = create_react_agent(llm, tools, prompt)\nexecutor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=15)"
    },
    "reflection_patterns_self_critique": {
      "description": "Agent reviews and improves its own output",
      "structure": "generate -> reflect -> revise (loop until satisfactory)",
      "pattern": "Generate output -> Evaluate quality -> If insufficient, reflect and revise -> Repeat",
      "use_when": "Quality improvement needed; Self-correction required; Iterative refinement",
      "implementation": {
        "langgraph_example": "def should_continue(state: State) -> str:\n    if state['iteration'] >= 3:\n        return 'end'\n    if state['quality_score'] >= 0.9:\n        return 'end'\n    return 'reflect'\n\ngraph.add_conditional_edges('revise', should_continue, {'end': END, 'reflect': 'reflect'})"
      },
      "best_practices": [
        "Set maximum iteration limits",
        "Define clear quality criteria",
        "Track improvement across iterations",
        "Use scoring functions for quality assessment"
      ],
      "code_example": "def should_continue(state: State) -> str:\n    if state['iteration'] >= 3:\n        return 'end'\n    if state['quality_score'] >= 0.9:\n        return 'end'\n    return 'reflect'\n\ngraph.add_conditional_edges('revise', should_continue, {'end': END, 'reflect': 'reflect'})"
    },
    "reflection_patterns_critic_agent": {
      "description": "Separate critic agent reviews generator agent output",
      "pattern": "Generator -> Critic -> Feedback -> Generator (revise)",
      "use_when": "Specialized critique needed; Separation of concerns; Multi-agent systems",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "reflection_patterns_iterative_refinement": {
      "description": "Multiple passes to refine output quality",
      "pattern": "Initial generation -> Refinement pass 1 -> Refinement pass 2 -> Final output",
      "use_when": "High-quality output required; Complex content generation; Code generation",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "planning_patterns_hierarchical_planning": {
      "description": "Break down high-level plan into sub-plans",
      "pattern": "High-level plan -> Sub-plans -> Actions -> Execute",
      "use_when": "Complex multi-step tasks; Long-horizon planning; Structured problem solving",
      "best_practices": [
        "Plan at appropriate abstraction levels",
        "Validate plan feasibility",
        "Adjust plan based on execution results"
      ],
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)"
    },
    "planning_patterns_replanning": {
      "description": "Revise plan based on execution feedback",
      "pattern": "Create plan -> Execute -> Evaluate -> Replan if needed",
      "use_when": "Dynamic environments; Uncertain outcomes; Adaptive workflows",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "planning_patterns_plan_execute": {
      "description": "Separate planning phase from execution phase",
      "pattern": "Plan all steps -> Execute plan -> Report results",
      "use_when": "Well-defined problems; Batch processing; Offline planning",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "planning_patterns_reactive_planning": {
      "description": "Plan incrementally as execution progresses",
      "pattern": "Plan next step -> Execute -> Plan next step -> Repeat",
      "use_when": "Dynamic environments; Real-time adaptation; Uncertain conditions",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "iterative_refinement_multi_pass_refinement": {
      "description": "Multiple passes to improve output",
      "pattern": "Pass 1: Generate -> Pass 2: Refine -> Pass 3: Polish -> Final",
      "use_when": "Content generation; Code writing; Analysis refinement",
      "best_practices": [
        "Limit number of passes",
        "Define refinement criteria",
        "Track improvement metrics"
      ],
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)"
    },
    "iterative_refinement_feedback_loop": {
      "description": "Use feedback to guide refinement",
      "pattern": "Generate -> Get feedback -> Refine based on feedback -> Repeat",
      "feedback_sources": [
        "Self-evaluation",
        "External critic",
        "User feedback",
        "Automated metrics"
      ],
      "use_when": "When building agents that need tool calling, multi-step reasoning, or structured workflows.",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "iterative_refinement_progressive_enhancement": {
      "description": "Start simple and add complexity iteratively",
      "pattern": "Basic version -> Add features -> Refine -> Enhance",
      "use_when": "Complex outputs; Incremental development; Risk mitigation",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "loop_control_iteration_limits": {
      "description": "Set maximum iterations to prevent infinite loops",
      "pattern": "Check iteration count -> Stop if limit reached",
      "best_practices": [
        "Set reasonable limits",
        "Log when limit reached",
        "Return partial results if needed"
      ],
      "use_when": "When building agents that need tool calling, multi-step reasoning, or structured workflows.",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)"
    },
    "loop_control_termination_conditions": {
      "description": "Define clear conditions for loop termination",
      "conditions": [
        "Task completion",
        "Quality threshold met",
        "Maximum iterations",
        "Error threshold exceeded",
        "User cancellation"
      ],
      "use_when": "When building agents that need tool calling, multi-step reasoning, or structured workflows.",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "loop_control_early_stopping": {
      "description": "Stop loop early when goal achieved",
      "pattern": "Check completion criteria -> Stop if met -> Continue otherwise",
      "benefits": [
        "Reduced cost",
        "Faster response",
        "Better user experience"
      ],
      "use_when": "When building agents that need tool calling, multi-step reasoning, or structured workflows.",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "error_recovery_retry_on_failure": {
      "description": "Retry failed operations with backoff",
      "pattern": "Execute -> On failure -> Wait -> Retry -> Max attempts",
      "use_when": "Transient failures; Network issues; Temporary errors",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "error_recovery_fallback_strategies": {
      "description": "Use alternative approaches when primary fails",
      "pattern": "Try primary -> On failure -> Try fallback -> Report",
      "use_when": "Critical operations; High reliability needed; Multiple options available",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)",
      "best_practices": [
        "Set max_iterations to prevent infinite agent loops",
        "Use structured output for reliable parsing of agent responses"
      ]
    },
    "error_recovery_error_propagation": {
      "description": "Handle and report errors appropriately",
      "pattern": "Catch error -> Log -> Report to user -> Continue or abort",
      "best_practices": [
        "Don't silently fail",
        "Provide error context",
        "Allow recovery when possible"
      ],
      "use_when": "When building agents that need tool calling, multi-step reasoning, or structured workflows.",
      "code_example": "from langchain_core.tools import tool\nfrom langchain_openai import ChatOpenAI\n\n@tool\ndef example_tool(query: str) -> str:\n    '''Example tool for agent use.'''\n    return f\"Result for: {query}\"\n\nllm = ChatOpenAI(model='gpt-4', temperature=0)\ntools = [example_tool]\nagent = llm.bind_tools(tools)"
    }
  },
  "best_practices": [
    "Set maximum iteration limits to prevent infinite loops and resource exhaustion",
    "Define clear termination conditions including task completion and quality thresholds",
    "Log all reasoning steps for transparency and debugging",
    "Handle tool execution errors gracefully with retry and fallback strategies",
    "Implement early stopping when goals are met to reduce costs and latency",
    "Use reflection patterns for quality improvement through self-critique",
    "Plan at appropriate abstraction levels - not too detailed, not too high-level",
    "Validate plans before execution to catch infeasible approaches early",
    "Track improvement metrics across iterations to measure refinement effectiveness",
    "Implement retry strategies with exponential backoff for transient failures",
    "Use structured outputs for consistent parsing of agent reasoning and actions",
    "Add observability with LangSmith tracing to monitor loop behavior",
    "Monitor loop performance and costs to optimize iteration efficiency",
    "Test with various inputs and edge cases to ensure robust behavior",
    "Provide clear error messages and recovery options for better user experience"
  ],
  "anti_patterns": [
    {
      "name": "No iteration limits",
      "problem": "Infinite loops and resource exhaustion",
      "fix": "Set max_iterations in all loops"
    },
    {
      "name": "No termination conditions",
      "problem": "Loops run indefinitely",
      "fix": "Define clear completion criteria"
    },
    {
      "name": "Silent failures",
      "problem": "Errors go unnoticed",
      "fix": "Log and report all errors"
    },
    {
      "name": "No reflection mechanism",
      "problem": "Poor quality outputs",
      "fix": "Implement self-critique or external review"
    },
    {
      "name": "Over-planning",
      "problem": "Delays execution unnecessarily",
      "fix": "Balance planning depth with execution speed"
    },
    {
      "name": "No error recovery",
      "problem": "Single failures break entire loop",
      "fix": "Implement retry and fallback strategies"
    },
    {
      "name": "Ignoring tool errors",
      "problem": "Incorrect results from failed tools",
      "fix": "Handle and report tool errors"
    },
    {
      "name": "No quality metrics",
      "problem": "Can't measure improvement",
      "fix": "Define and track quality scores"
    }
  ]
}