{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "id": "speech-processing-patterns",
  "name": "Speech Processing Patterns",
  "title": "Speech Processing Patterns",
  "description": "Patterns for speech-to-text transcription, text-to-speech synthesis, real-time transcription, and audio analysis",
  "version": "1.0.0",
  "category": "ai-ml",
  "axiomAlignment": {
    "A1_verifiability": "Transcripts can be verified against source audio and confidence scores",
    "A2_user_primacy": "Speech processing serves accessibility and user intent",
    "A3_transparency": "Engine choices and preprocessing steps are explicit",
    "A4_non_harm": "Content moderation and filtering protect against harmful audio",
    "A5_consistency": "Unified patterns for STT, TTS, and real-time transcription"
  },
  "related_skills": [
    "speech-processing",
    "vision-agents",
    "applying-rag-patterns",
    "ocr-processing"
  ],
  "related_knowledge": [
    "vision-patterns.json",
    "ocr-patterns.json",
    "applying-rag-patterns.json",
    "langchain-patterns.json"
  ],
  "patterns": {
    "speech_to_text": {
      "whisper": {
        "description": "OpenAI Whisper - offline, high-accuracy transcription",
        "use_when": "Offline processing, High accuracy needed, Multiple languages",
        "model_sizes": [
          "tiny",
          "base",
          "small",
          "medium",
          "large"
        ],
        "pros": [
          "Very high accuracy",
          "99+ languages",
          "Free",
          "Offline"
        ],
        "cons": [
          "Slower than cloud APIs",
          "GPU recommended for large models"
        ],
        "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "google_cloud_speech": {
        "description": "Google Cloud Speech-to-Text API",
        "use_when": "Real-time transcription, Highest accuracy, Cloud infrastructure",
        "pros": [
          "Very high accuracy",
          "Real-time streaming",
          "Word timestamps"
        ],
        "cons": [
          "Requires internet",
          "Paid service",
          "API rate limits"
        ],
        "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "azure_speech": {
        "description": "Azure Cognitive Services Speech",
        "use_when": "Azure ecosystem, Multi-language support, Custom models",
        "pros": [
          "High accuracy",
          "Custom models",
          "Speaker diarization"
        ],
        "cons": [
          "Paid service",
          "Requires internet"
        ],
        "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "description": "Pattern for speech patterns - implement with domain-specific logic.",
      "use_when": "When implementing this pattern in your AI/ML application",
      "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
      "best_practices": [
        "Use Whisper for offline, high-accuracy transcription",
        "Preprocess audio (normalize, remove noise) before transcription",
        "Use voice activity detection to skip silent segments",
        "Choose appropriate model size based on accuracy vs. speed needs",
        "Cache transcriptions for repeated audio files"
      ]
    },
    "text_to_speech": {
      "gtts": {
        "description": "Google Text-to-Speech (free, requires internet)",
        "use_when": "Simple TTS, Multiple languages, Free solution",
        "pros": [
          "Free",
          "100+ languages",
          "Easy to use"
        ],
        "cons": [
          "Requires internet",
          "Limited voice options"
        ],
        "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "pyttsx3": {
        "description": "Offline TTS using system voices",
        "use_when": "Offline operation, System integration, No internet",
        "pros": [
          "Offline",
          "Free",
          "System voices"
        ],
        "cons": [
          "Lower quality",
          "Limited languages"
        ],
        "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "azure_speech_synthesis": {
        "description": "Azure Speech Synthesis with neural voices",
        "use_when": "High quality needed, Natural voices, Production apps",
        "pros": [
          "High quality",
          "Natural voices",
          "SSML support"
        ],
        "cons": [
          "Paid service",
          "Requires internet"
        ],
        "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "description": "Pattern for speech patterns - implement with domain-specific logic.",
      "use_when": "When implementing this pattern in your AI/ML application",
      "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
      "best_practices": [
        "Use Whisper for offline, high-accuracy transcription",
        "Preprocess audio (normalize, remove noise) before transcription",
        "Use voice activity detection to skip silent segments",
        "Choose appropriate model size based on accuracy vs. speed needs",
        "Cache transcriptions for repeated audio files"
      ]
    },
    "real_time_transcription": {
      "streaming_whisper": {
        "description": "Real-time transcription using Whisper with audio chunks",
        "pattern": "Record audio in chunks, transcribe each chunk, combine results",
        "chunk_duration": "5-10 seconds recommended",
        "use_when": "When implementing this pattern in your AI/ML application",
        "code_example": "Record audio in chunks, transcribe each chunk, combine results",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "voice_activity_detection": {
        "description": "Detect speech segments to skip silence",
        "library": "webrtcvad",
        "pattern": "Process audio frames, detect speech, only transcribe speech segments",
        "use_when": "Long audio files, Reducing processing time",
        "code_example": "Process audio frames, detect speech, only transcribe speech segments",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "continuous_streaming": {
        "description": "Continuous audio stream transcription",
        "pattern": "Use threading for parallel recording/transcription, maintain audio buffer",
        "use_when": "When implementing this pattern in your AI/ML application",
        "code_example": "Use threading for parallel recording/transcription, maintain audio buffer",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "description": "Pattern for speech patterns - implement with domain-specific logic.",
      "use_when": "When implementing this pattern in your AI/ML application",
      "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
      "best_practices": [
        "Use Whisper for offline, high-accuracy transcription",
        "Preprocess audio (normalize, remove noise) before transcription",
        "Use voice activity detection to skip silent segments",
        "Choose appropriate model size based on accuracy vs. speed needs",
        "Cache transcriptions for repeated audio files"
      ]
    },
    "audio_analysis": {
      "silence_detection": {
        "description": "Detect silent segments in audio",
        "library": "pydub",
        "pattern": "split_on_silence with threshold and min_silence_len",
        "use_when": "Segmenting audio, Removing silence",
        "code_example": "split_on_silence with threshold and min_silence_len",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "normalization": {
        "description": "Normalize audio levels to target dBFS",
        "pattern": "Calculate current dBFS, apply gain to reach target",
        "target_dBFS": "-20.0 dBFS recommended",
        "use_when": "When implementing this pattern in your AI/ML application",
        "code_example": "Calculate current dBFS, apply gain to reach target",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "segmentation": {
        "description": "Split audio into fixed-duration segments",
        "pattern": "Iterate through audio, extract segments of fixed duration",
        "use_when": "Batch processing, Chunking for models",
        "code_example": "Iterate through audio, extract segments of fixed duration",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "audio_properties": {
        "description": "Analyze audio file properties",
        "properties": [
          "duration",
          "sample_rate",
          "channels",
          "rms",
          "dBFS"
        ],
        "use_when": "When implementing this pattern in your AI/ML application",
        "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "description": "Pattern for speech patterns - implement with domain-specific logic.",
      "use_when": "When implementing this pattern in your AI/ML application",
      "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
      "best_practices": [
        "Use Whisper for offline, high-accuracy transcription",
        "Preprocess audio (normalize, remove noise) before transcription",
        "Use voice activity detection to skip silent segments",
        "Choose appropriate model size based on accuracy vs. speed needs",
        "Cache transcriptions for repeated audio files"
      ]
    },
    "word_timestamps": {
      "whisper_timestamps": {
        "description": "Get word-level timestamps from Whisper",
        "pattern": "Enable word_timestamps=True, extract from segments",
        "use_when": "Precise alignment, Subtitle generation",
        "code_example": "Enable word_timestamps=True, extract from segments",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "google_cloud_timestamps": {
        "description": "Word-level timestamps from Google Cloud Speech",
        "pattern": "Enable enable_word_time_offsets, extract from results",
        "use_when": "High precision needed, Cloud processing",
        "code_example": "Enable enable_word_time_offsets, extract from results",
        "best_practices": [
          "Use Whisper for offline, high-accuracy transcription",
          "Preprocess audio (normalize, remove noise) before transcription",
          "Use voice activity detection to skip silent segments",
          "Choose appropriate model size based on accuracy vs. speed needs",
          "Cache transcriptions for repeated audio files"
        ]
      },
      "description": "Pattern for speech patterns - implement with domain-specific logic.",
      "use_when": "When implementing this pattern in your AI/ML application",
      "code_example": "# Implement pattern based on description\n# Use appropriate imports and domain-specific logic\nresult = process_data(input_data)",
      "best_practices": [
        "Use Whisper for offline, high-accuracy transcription",
        "Preprocess audio (normalize, remove noise) before transcription",
        "Use voice activity detection to skip silent segments",
        "Choose appropriate model size based on accuracy vs. speed needs",
        "Cache transcriptions for repeated audio files"
      ]
    }
  },
  "tool_comparison": {
    "whisper": {
      "type": "STT",
      "accuracy": "Very High",
      "languages": "99+",
      "cost": "Free",
      "offline": true
    },
    "google_cloud_speech": {
      "type": "STT",
      "accuracy": "Very High",
      "languages": "50+",
      "cost": "Paid",
      "offline": false
    },
    "azure_speech": {
      "type": "STT/TTS",
      "accuracy": "Very High",
      "languages": "50+",
      "cost": "Paid",
      "offline": false
    },
    "gtts": {
      "type": "TTS",
      "accuracy": "High",
      "languages": "100+",
      "cost": "Free",
      "offline": false
    },
    "pyttsx3": {
      "type": "TTS",
      "accuracy": "Medium",
      "languages": "System",
      "cost": "Free",
      "offline": true
    }
  },
  "best_practices": [
    "Use Whisper for offline, high-accuracy transcription",
    "Preprocess audio (normalize, remove noise) before transcription",
    "Use voice activity detection to skip silent segments",
    "Choose appropriate model size based on accuracy vs. speed needs",
    "Cache transcriptions for repeated audio files",
    "Use word-level timestamps for precise alignment",
    "Normalize audio levels before processing",
    "Handle multiple speakers with speaker diarization when needed",
    "Convert audio to required sample rate (16kHz for Whisper)",
    "Use appropriate chunk sizes for real-time processing (5-10 seconds)"
  ],
  "anti_patterns": [
    {
      "name": "No audio preprocessing",
      "problem": "Lower transcription accuracy",
      "fix": "Normalize, denoise before transcription"
    },
    {
      "name": "Wrong sample rate",
      "problem": "Poor transcription quality",
      "fix": "Convert to model's required rate (16kHz for Whisper)"
    },
    {
      "name": "Processing entire file",
      "problem": "Slow, inefficient",
      "fix": "Use VAD to segment speech regions"
    },
    {
      "name": "Ignoring confidence scores",
      "problem": "Incorrect transcriptions included",
      "fix": "Filter low-confidence transcriptions"
    },
    {
      "name": "No language specification",
      "problem": "Lower accuracy on non-English",
      "fix": "Detect or specify language for better accuracy"
    },
    {
      "name": "Large model for simple tasks",
      "problem": "Unnecessary slow processing",
      "fix": "Use smaller models (base/tiny) when speed matters"
    },
    {
      "name": "No error handling",
      "problem": "Crashes on API failures or format errors",
      "fix": "Handle API failures and audio format errors gracefully"
    }
  ]
}
