{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "id": "google-agent-development-kit-patterns",
  "name": "Google Agent Development Kit Patterns",
  "title": "Google ADK Patterns",
  "description": "Best practices and patterns for Google Agent Development Kit (ADK) - building agents with Gemini models, LlmAgent, WorkflowAgent, and Google's tool ecosystem",
  "version": "1.0.0",
  "last_updated": "2026-02-11",
  "category": "agent-patterns",
  "axiomAlignment": {
    "A1_verifiability": "AgentOps and AG-UI enable verification of agent behavior",
    "A2_user_primacy": "AG-UI provides user control and transparency",
    "A3_transparency": "Agent definitions and tool usage are explicit",
    "A4_non_harm": "Safety settings and guardrails prevent harmful outputs",
    "A5_consistency": "Unified ADK patterns across Gemini-powered agents"
  },
  "related_skills": [
    "tool-usage",
    "agentic-loops",
    "vision-agents"
  ],
  "related_knowledge": [
    "langchain-patterns.json",
    "anthropic-patterns.json",
    "openai-agents-sdk-patterns.json"
  ],
  "patterns": {
    "llm_agent": {
      "description": "Create an LLM-powered agent with Google ADK",
      "use_when": "Building agents that use Gemini models for reasoning",
      "code_example": "from google_adk import LlmAgent, Gemini\n\n# Create agent with Gemini model\nagent = LlmAgent(\n    name='Research Assistant',\n    model=Gemini('gemini-2.5-flash'),\n    system_instruction='''You are a helpful research assistant.\n    You can search the web, analyze documents, and provide insights.\n    Always cite your sources and be accurate.''',\n    tools=[google_search, analyze_document]\n)\n\n# Run agent\nresult = await agent.run('Research the latest AI developments')\nprint(result.response)\n\n# Access tool usage\nfor tool_call in result.tool_calls:\n    print(f'Tool: {tool_call.name}')\n    print(f'Args: {tool_call.args}')\n    print(f'Result: {tool_call.result}')",
      "best_practices": [
        "Use Gemini 2.5 Flash for fast, cost-effective agents",
        "Write clear system instructions",
        "Choose appropriate tools for agent capabilities",
        "Monitor token usage and costs"
      ],
      "key_properties": {
        "name": "Agent identifier",
        "model": "Gemini model to use",
        "system_instruction": "System prompt defining behavior",
        "tools": "List of available tools",
        "safety_settings": "Content safety configuration"
      }
    },
    "workflow_agent": {
      "description": "Create multi-step workflow agents",
      "use_when": "Complex tasks requiring structured execution flow",
      "code_example": "from google_adk import WorkflowAgent, Step, Condition\n\n# Define workflow steps\nclass ResearchWorkflow(WorkflowAgent):\n    \n    @Step(name='gather_requirements')\n    async def gather_requirements(self, query: str) -> dict:\n        \"\"\"Extract research requirements from query.\"\"\"\n        result = await self.llm.generate(\n            f'Extract research requirements from: {query}'\n        )\n        return {'requirements': result.text}\n    \n    @Step(name='search_sources')\n    async def search_sources(self, requirements: dict) -> list:\n        \"\"\"Search for relevant sources.\"\"\"\n        sources = await self.tools.google_search(\n            requirements['requirements']\n        )\n        return sources\n    \n    @Step(name='analyze_sources')\n    @Condition(lambda result: len(result) >= 3)  # Only if enough sources\n    async def analyze_sources(self, sources: list) -> dict:\n        \"\"\"Analyze gathered sources.\"\"\"\n        analysis = await self.llm.generate(\n            f'Analyze these sources: {sources}'\n        )\n        return {'analysis': analysis.text}\n    \n    @Step(name='generate_report')\n    async def generate_report(self, analysis: dict) -> str:\n        \"\"\"Generate final report.\"\"\"\n        report = await self.llm.generate(\n            f'Write a report based on: {analysis}'\n        )\n        return report.text\n\n# Run workflow\nworkflow = ResearchWorkflow(model=Gemini('gemini-2.5-pro'))\nresult = await workflow.run('Research quantum computing trends')",
      "best_practices": [
        "Break complex tasks into discrete steps",
        "Use conditions for conditional execution",
        "Handle step failures gracefully",
        "Log workflow progress for debugging"
      ]
    },
    "gemini_tools": {
      "description": "Built-in tools available with Gemini models",
      "use_when": "Agents need Google-native capabilities like search, code execution, or web fetching",
      "code_example": "from google_adk import LlmAgent, Gemini\nfrom google_adk.tools import GoogleSearch, CodeExecution, WebFetch\n\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-flash'),\n    tools=[GoogleSearch(), CodeExecution(allowed_imports=['numpy']), WebFetch()]\n)\nresult = await agent.run('Search for latest AI news and summarize')",
      "tools": {
        "google_search": {
          "description": "Search the web using Google Search",
          "code_example": "from google_adk import LlmAgent, Gemini\nfrom google_adk.tools import GoogleSearch\n\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-flash'),\n    tools=[GoogleSearch()]\n)\n\nresult = await agent.run('What are the latest AI news?')"
        },
        "code_execution": {
          "description": "Execute Python code in a sandboxed environment",
          "code_example": "from google_adk.tools import CodeExecution\n\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-flash'),\n    tools=[CodeExecution(allowed_imports=['numpy', 'pandas'])]\n)\n\nresult = await agent.run('Calculate the mean of [1, 2, 3, 4, 5]')"
        },
        "computer_use": {
          "description": "Interact with computer interfaces",
          "code_example": "from google_adk.tools import ComputerUse\n\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-pro'),\n    tools=[ComputerUse(display_size=(1920, 1080))]\n)\n\nresult = await agent.run('Open settings and change theme to dark')"
        },
        "web_fetch": {
          "description": "Fetch content from web pages",
          "code_example": "from google_adk.tools import WebFetch\n\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-flash'),\n    tools=[WebFetch(allowed_domains=['*.github.com'])]\n)\n\nresult = await agent.run('Get the README from github.com/google/adk')"
        }
      },
      "best_practices": [
        "Use GoogleSearch for real-time information",
        "Sandbox code execution with allowed_imports",
        "Restrict WebFetch to trusted domains",
        "Require human approval for ComputerUse"
      ]
    },
    "custom_tools": {
      "description": "Create custom tools for agents",
      "use_when": "Agents need domain-specific capabilities",
      "code_example": "from google_adk import LlmAgent, Gemini, tool\nfrom pydantic import BaseModel, Field\n\n# Simple function tool\n@tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get current weather for a city.\"\"\"\n    return f'The weather in {city} is sunny, 72\u00b0F'\n\n# Tool with Pydantic schema\nclass DatabaseQuery(BaseModel):\n    table: str = Field(description='Table name to query')\n    conditions: dict = Field(description='Query conditions')\n    limit: int = Field(default=10, ge=1, le=100)\n\n@tool\nasync def query_database(params: DatabaseQuery) -> list:\n    \"\"\"Query the database with conditions.\"\"\"\n    results = await db.query(\n        table=params.table,\n        where=params.conditions,\n        limit=params.limit\n    )\n    return results\n\n# Multimodal tool\n@tool\nasync def analyze_image(image_url: str, question: str) -> str:\n    \"\"\"Analyze an image and answer a question about it.\"\"\"\n    image = await fetch_image(image_url)\n    result = await gemini_vision.generate(\n        image=image,\n        prompt=question\n    )\n    return result.text\n\n# Create agent with custom tools\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-flash'),\n    tools=[get_weather, query_database, analyze_image]\n)",
      "best_practices": [
        "Use @tool decorator for automatic schema",
        "Provide detailed docstrings",
        "Use Pydantic for complex inputs",
        "Handle errors gracefully"
      ]
    },
    "multimodal_agents": {
      "description": "Agents that process images, audio, and video",
      "use_when": "Tasks involving visual or audio understanding",
      "code_example": "from google_adk import LlmAgent, Gemini\nfrom google_adk.types import Image, Audio, Video\n\n# Multimodal agent\nagent = LlmAgent(\n    name='Visual Assistant',\n    model=Gemini('gemini-2.5-pro'),\n    system_instruction='You can analyze images, audio, and video.'\n)\n\n# Analyze image\nimage = Image.from_file('chart.png')\nresult = await agent.run(\n    'Describe the trends shown in this chart',\n    attachments=[image]\n)\n\n# Analyze video\nvideo = Video.from_file('presentation.mp4')\nresult = await agent.run(\n    'Summarize the key points from this presentation',\n    attachments=[video]\n)\n\n# Analyze audio\naudio = Audio.from_file('meeting.mp3')\nresult = await agent.run(\n    'Transcribe and summarize this meeting',\n    attachments=[audio]\n)\n\n# Multiple attachments\nresult = await agent.run(\n    'Compare these two product designs',\n    attachments=[\n        Image.from_file('design_a.png'),\n        Image.from_file('design_b.png')\n    ]\n)",
      "best_practices": [
        "Use Gemini Pro for complex multimodal tasks",
        "Compress large media before sending",
        "Handle unsupported formats gracefully",
        "Set reasonable timeouts for video processing"
      ]
    },
    "ag_ui": {
      "description": "Agent-User Interface protocol for transparent interactions",
      "use_when": "Building user-facing agents with visibility into reasoning",
      "code_example": "from google_adk import LlmAgent, Gemini\nfrom google_adk.ag_ui import AgUI, ThoughtPanel, ToolPanel\n\n# Create AG-UI enabled agent\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-flash'),\n    ag_ui=AgUI(\n        show_thoughts=True,       # Display reasoning\n        show_tool_calls=True,     # Display tool usage\n        allow_interrupts=True,    # User can interrupt\n        approval_required=['delete_file', 'send_email']  # Require approval\n    )\n)\n\n# Stream with UI events\nasync for event in agent.stream_with_ui('Organize my files'):\n    if event.type == 'thought':\n        print(f'Thinking: {event.content}')\n    elif event.type == 'tool_call':\n        print(f'Using tool: {event.tool_name}')\n        if event.requires_approval:\n            approved = await get_user_approval(event)\n            event.set_approval(approved)\n    elif event.type == 'response':\n        print(f'Response: {event.content}')\n    elif event.type == 'interrupt':\n        # Handle user interrupt\n        break",
      "best_practices": [
        "Enable show_thoughts for transparency",
        "Require approval for sensitive actions",
        "Handle interrupts gracefully",
        "Stream events for real-time UX"
      ]
    },
    "agent_ops": {
      "description": "Observability and monitoring for agents",
      "use_when": "Production agents need monitoring and debugging",
      "code_example": "from google_adk import LlmAgent, Gemini\nfrom google_adk.ops import AgentOps, CloudTrace, CloudLogging\n\n# Configure observability\nops = AgentOps(\n    tracing=CloudTrace(project='my-project'),\n    logging=CloudLogging(project='my-project'),\n    metrics=True,\n    sample_rate=1.0  # 100% sampling in development\n)\n\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-flash'),\n    ops=ops\n)\n\n# Run with automatic tracing\nresult = await agent.run('Help with task')\n\n# Access trace data\nprint(f'Trace ID: {result.trace_id}')\nprint(f'Duration: {result.duration_ms}ms')\nprint(f'Token usage: {result.token_usage}')\nprint(f'Cost: ${result.estimated_cost}')\n\n# Custom spans\nwith ops.span('custom_operation'):\n    # Custom logic\n    pass\n\n# Log events\nops.log('user_interaction', {\n    'query': 'user query',\n    'response_time_ms': 150\n})",
      "best_practices": [
        "Enable tracing in all environments",
        "Export to Cloud Trace for distributed tracing",
        "Monitor token usage and costs",
        "Set up alerts for errors and latency"
      ]
    },
    "safety_settings": {
      "description": "Configure content safety for agents",
      "use_when": "Production agents need content filtering",
      "code_example": "from google_adk import LlmAgent, Gemini\nfrom google_adk.safety import SafetySettings, HarmCategory, HarmBlockThreshold\n\n# Configure safety\nsafety = SafetySettings({\n    HarmCategory.HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    HarmCategory.HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    HarmCategory.SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    HarmCategory.DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n})\n\nagent = LlmAgent(\n    model=Gemini('gemini-2.5-flash'),\n    safety_settings=safety\n)\n\n# Handle blocked responses\ntry:\n    result = await agent.run('user query')\nexcept SafetyBlockError as e:\n    print(f'Response blocked: {e.category}')\n    # Provide safe fallback response",
      "best_practices": [
        "Always configure safety settings in production",
        "Use stricter thresholds for sensitive applications",
        "Handle SafetyBlockError gracefully",
        "Log blocked responses for review"
      ]
    }
  },
  "best_practices": [
    "Use Gemini 2.5 Flash for fast, cost-effective agents",
    "Use Gemini 2.5 Pro for complex reasoning and multimodal tasks",
    "Write clear system instructions that define agent behavior",
    "Use @tool decorator with Pydantic for type-safe tools",
    "Enable AG-UI for transparent user-facing agents",
    "Configure AgentOps for production observability",
    "Set appropriate safety settings for content filtering",
    "Require user approval for sensitive actions",
    "Use WorkflowAgent for complex multi-step tasks",
    "Stream events for real-time user experience"
  ],
  "anti_patterns": [
    {
      "name": "Wrong Model Selection",
      "problem": "Using Pro for simple tasks wastes resources",
      "fix": "Use Flash for simple tasks, Pro for complex reasoning"
    },
    {
      "name": "Missing Safety Settings",
      "problem": "Agent can produce harmful content",
      "fix": "Always configure SafetySettings in production"
    },
    {
      "name": "No Observability",
      "problem": "Cannot debug issues or track costs",
      "fix": "Enable AgentOps with tracing and logging"
    },
    {
      "name": "Uncontrolled Tool Access",
      "problem": "Agent can perform destructive actions",
      "fix": "Use AG-UI approval_required for sensitive tools"
    },
    {
      "name": "Blocking on Multimodal",
      "problem": "Large media causes timeouts",
      "fix": "Compress media and set appropriate timeouts"
    }
  ],
  "sources": [
    "https://developers.google.com/agent-development-kit",
    "https://ai.google.dev/gemini-api/docs",
    "https://github.com/google/adk"
  ]
}