{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "id": "document-processing-patterns",
  "name": "Document Processing Patterns",
  "title": "Document Processing Patterns",
  "description": "Patterns for document ingestion, extraction, and processing using Docling, Unstructured.io, and other tools",
  "version": "1.0.0",
  "category": "specialized",
  "axiomAlignment": {
    "A1_verifiability": "Proper extraction preserves source information",
    "A3_transparency": "Processing steps and metadata are tracked",
    "A2_user_primacy": "Patterns prioritize user needs and practical outcomes",
    "A4_non_harm": "Patterns include safety considerations and error handling",
    "A5_consistency": "Patterns follow established conventions and standards"
  },
  "docling_patterns": {
    "basic_usage": {
      "description": "Basic document processing with Docling",
      "use_for": "PDF, Word, PowerPoint, Excel extraction with structure preservation",
      "code_example": "from docling.document_converter import DocumentConverter\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\n# Create converter\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfPipelineOptions(\n            do_ocr=True,\n            do_table_structure=True\n        )\n    }\n)\n\n# Convert document\nresult = converter.convert('document.pdf')\n\n# Access structured output\nprint(result.document.export_to_json())\n\n# Access text\nprint(result.document.text)",
      "best_practices": [
        "Enable OCR for scanned PDFs",
        "Enable table_structure for table extraction",
        "Use format_options for specific file types",
        "Access structured output for better parsing"
      ],
      "use_when": "PDF, Word, PowerPoint, Excel extraction with structure preservation"
    },
    "pdf_extraction": {
      "description": "Extract content from PDFs with structure",
      "code_example": "from docling.document_converter import DocumentConverter\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfPipelineOptions(\n            do_ocr=True,\n            do_table_structure=True,\n            table_structure_options={\n                'method': 'lattice',  # or 'stream'\n                'extract_images': True\n            }\n        )\n    }\n)\n\n# Convert PDF\nresult = converter.convert('document.pdf')\n\n# Access tables\nfor table in result.document.tables:\n    print(f'Table: {table}')\n    print(f'Data: {table.data}')\n\n# Access images\nfor image in result.document.images:\n    print(f'Image: {image}')\n\n# Access text with structure\nfor section in result.document.sections:\n    print(f'Section: {section.title}')\n    print(f'Content: {section.text}')",
      "best_practices": [
        "Use OCR for scanned documents",
        "Extract tables for structured data",
        "Preserve document structure (sections, headings)",
        "Handle multi-column layouts"
      ],
      "use_when": "Apply when implementing pdf extraction in integration context"
    },
    "word_document_extraction": {
      "description": "Extract from Word documents",
      "code_example": "from docling.document_converter import DocumentConverter\nfrom docling.datamodel.base_models import InputFormat\n\nconverter = DocumentConverter()\n\n# Convert Word document\nresult = converter.convert('document.docx')\n\n# Access content\nprint(result.document.text)\n\n# Access structure\nfor section in result.document.sections:\n    print(f'Heading: {section.title}')\n    print(f'Content: {section.text}')",
      "best_practices": [
        "Preserves Word document structure",
        "Extracts tables and images",
        "Maintains formatting metadata"
      ],
      "use_when": "Apply when implementing word document extraction in integration context"
    },
    "batch_processing": {
      "description": "Process multiple documents",
      "code_example": "from docling.document_converter import DocumentConverter\nfrom pathlib import Path\n\nconverter = DocumentConverter()\n\n# Process directory\ninput_dir = Path('./documents')\noutput_dir = Path('./processed')\n\nfor pdf_file in input_dir.glob('*.pdf'):\n    try:\n        result = converter.convert(str(pdf_file))\n        \n        # Save processed content\n        output_file = output_dir / f'{pdf_file.stem}.json'\n        with open(output_file, 'w') as f:\n            f.write(result.document.export_to_json())\n    except Exception as e:\n        print(f'Error processing {pdf_file}: {e}')",
      "best_practices": [
        "Process files in batch",
        "Handle errors per document",
        "Save processed output",
        "Track processing status"
      ],
      "use_when": "Apply when implementing batch processing in integration context"
    }
  },
  "unstructured_patterns": {
    "basic_usage": {
      "description": "Basic document processing with Unstructured.io",
      "use_for": "PDF, HTML, images, and various document formats",
      "code_example": "from unstructured.partition.auto import partition\nfrom unstructured.chunking.title import chunk_by_title\n\n# Partition document\n elements = partition(\n    filename='document.pdf',\n    strategy='hi_res',  # High resolution for better OCR\n    infer_table_structure=True\n)\n\n# Access elements\nfor element in elements:\n    print(f'Type: {element.category}')\n    print(f'Text: {element.text}')\n    if hasattr(element, 'metadata'):\n        print(f'Metadata: {element.metadata}')\n\n# Chunk by title\nchunks = chunk_by_title(elements)\nfor chunk in chunks:\n    print(chunk.text)",
      "best_practices": [
        "Use strategy='hi_res' for better quality",
        "Enable infer_table_structure for tables",
        "Chunk by title for better structure",
        "Access element metadata"
      ],
      "use_when": "PDF, HTML, images, and various document formats"
    },
    "pdf_extraction": {
      "description": "Extract from PDFs with Unstructured",
      "code_example": "from unstructured.partition.pdf import partition_pdf\nfrom unstructured.chunking.title import chunk_by_title\n\n# Partition PDF\n elements = partition_pdf(\n    filename='document.pdf',\n    strategy='hi_res',\n    infer_table_structure=True,\n    extract_images_in_pdf=True,\n    extract_image_block_types=['Image', 'Table']\n)\n\n# Process elements\nfor element in elements:\n    if element.category == 'Table':\n        print(f'Table: {element.metadata.text_as_html}')\n    elif element.category == 'Image':\n        print(f'Image: {element.metadata.image_path}')\n    else:\n        print(f'Text: {element.text}')\n\n# Chunk with title awareness\nchunks = chunk_by_title(elements, max_characters=1000)\nfor chunk in chunks:\n    print(f'Chunk: {chunk.text[:200]}...')",
      "best_practices": [
        "Use hi_res strategy for complex layouts",
        "Extract tables as HTML for structure",
        "Extract images when needed",
        "Chunk by title for semantic coherence"
      ],
      "use_when": "Apply when implementing pdf extraction in integration context"
    },
    "html_extraction": {
      "description": "Extract from HTML documents",
      "code_example": "from unstructured.partition.html import partition_html\n\n# Partition HTML\n elements = partition_html(\n    url='https://example.com',\n    # or filename='page.html'\n)\n\n# Process elements\nfor element in elements:\n    print(f'Type: {element.category}')\n    print(f'Text: {element.text}')\n    if element.category == 'Title':\n        print(f'Title: {element.text}')",
      "best_practices": [
        "Use for web scraping",
        "Preserves HTML structure",
        "Extracts titles, headings, paragraphs",
        "Handles nested HTML"
      ],
      "use_when": "Apply when implementing html extraction in integration context"
    },
    "image_extraction": {
      "description": "Extract text from images",
      "code_example": "from unstructured.partition.image import partition_image\n\n# Partition image (OCR)\n elements = partition_image(\n    filename='image.png',\n    strategy='ocr_only'\n)\n\n# Access extracted text\nfor element in elements:\n    print(element.text)\n\n# With layout detection\n elements = partition_image(\n    filename='image.png',\n    strategy='hi_res',  # Layout + OCR\n    infer_table_structure=True\n)",
      "best_practices": [
        "Use ocr_only for simple text extraction",
        "Use hi_res for complex layouts",
        "Enable table structure for tables in images",
        "Handle different image formats"
      ],
      "use_when": "Apply when implementing image extraction in integration context"
    },
    "chunking_strategies": {
      "description": "Chunk documents with Unstructured",
      "code_example": "from unstructured.partition.auto import partition\nfrom unstructured.chunking.title import chunk_by_title\nfrom unstructured.chunking.basic import chunk_elements\n\n# Partition document\n elements = partition('document.pdf')\n\n# Chunk by title (preserves structure)\nchunks = chunk_by_title(\n    elements,\n    max_characters=1000,\n    combine_text_under_n_chars=200,\n    new_after_n_chars=800\n)\n\n# Basic chunking\nbasic_chunks = chunk_elements(\n    elements,\n    max_characters=1000,\n    overlap=200\n)\n\n# Access chunks\nfor chunk in chunks:\n    print(f'Chunk: {chunk.text}')\n    print(f'Metadata: {chunk.metadata}')",
      "best_practices": [
        "Use chunk_by_title for structured documents",
        "Set max_characters based on embedding model",
        "Use overlap for context preservation",
        "Access chunk metadata for citations"
      ],
      "use_when": "Apply when implementing chunking strategies in integration context"
    }
  },
  "pdf_extraction_patterns": {
    "pypdf_extraction": {
      "description": "Basic PDF extraction with PyPDF",
      "code_example": "from pypdf import PdfReader\n\n# Read PDF\nreader = PdfReader('document.pdf')\n\n# Extract text from all pages\ntext = ''\nfor page in reader.pages:\n    text += page.extract_text() + '\\n'\n\nprint(text)\n\n# Extract metadata\nmetadata = reader.metadata\nprint(f'Title: {metadata.title}')\nprint(f'Author: {metadata.author}')",
      "best_practices": [
        "Simple for text-only PDFs",
        "Doesn't handle scanned PDFs well",
        "No structure preservation",
        "Use for simple extraction needs"
      ],
      "use_when": "Apply when implementing pypdf extraction in integration context"
    },
    "pdfplumber_extraction": {
      "description": "Extract PDFs with table support",
      "code_example": "import pdfplumber\n\n# Extract with pdfplumber\nwith pdfplumber.open('document.pdf') as pdf:\n    text = ''\n    tables = []\n    \n    for page in pdf.pages:\n        # Extract text\n        page_text = page.extract_text()\n        text += page_text + '\\n'\n        \n        # Extract tables\n        page_tables = page.extract_tables()\n        for table in page_tables:\n            tables.append(table)\n            print(f'Table: {table}')\n\nprint(text)",
      "best_practices": [
        "Good for table extraction",
        "Better layout detection than PyPDF",
        "Still struggles with scanned PDFs",
        "Use for PDFs with tables"
      ],
      "use_when": "Apply when implementing pdfplumber extraction in integration context"
    },
    "ocr_pdf_extraction": {
      "description": "Extract text from scanned PDFs using OCR",
      "code_example": "from pdf2image import convert_from_path\nimport pytesseract\nfrom PIL import Image\n\n# Convert PDF pages to images\npages = convert_from_path('scanned_document.pdf', dpi=300)\n\n# OCR each page\nextracted_text = []\nfor i, page in enumerate(pages):\n    # OCR\n    text = pytesseract.image_to_string(page, lang='eng')\n    extracted_text.append(text)\n    print(f'Page {i+1}: {text[:200]}...')\n\n# Combine text\nfull_text = '\\n\\n'.join(extracted_text)",
      "best_practices": [
        "Use for scanned PDFs",
        "Set appropriate DPI (300 recommended)",
        "Specify language for OCR",
        "May require preprocessing for better results"
      ],
      "use_when": "Apply when implementing ocr pdf extraction in integration context"
    }
  },
  "html_extraction_patterns": {
    "beautifulsoup_extraction": {
      "description": "Extract content from HTML",
      "code_example": "from bs4 import BeautifulSoup\nimport requests\n\n# Fetch HTML\nresponse = requests.get('https://example.com')\nhtml = response.text\n\n# Parse HTML\nsoup = BeautifulSoup(html, 'html.parser')\n\n# Extract text\n# Remove script and style elements\nfor script in soup(['script', 'style']):\n    script.decompose()\n\ntext = soup.get_text()\n\n# Extract specific elements\nheadings = [h.get_text() for h in soup.find_all(['h1', 'h2', 'h3'])]\nparagraphs = [p.get_text() for p in soup.find_all('p')]\nlinks = [a.get('href') for a in soup.find_all('a', href=True)]",
      "best_practices": [
        "Remove script/style tags",
        "Extract structured elements",
        "Handle encoding issues",
        "Use for simple HTML extraction"
      ],
      "use_when": "Apply when implementing beautifulsoup extraction in integration context"
    },
    "readability_extraction": {
      "description": "Extract main content from HTML",
      "code_example": "from readability import Document\nimport requests\n\n# Fetch HTML\nresponse = requests.get('https://example.com')\nhtml = response.text\n\n# Extract main content\ndoc = Document(html)\nmain_content = doc.summary()\n\n# Parse main content\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(main_content, 'html.parser')\ntext = soup.get_text()",
      "best_practices": [
        "Removes navigation, ads, etc.",
        "Extracts main article content",
        "Good for news articles, blog posts",
        "May miss some content"
      ],
      "use_when": "Apply when implementing readability extraction in integration context"
    }
  },
  "image_extraction_patterns": {
    "pytesseract_ocr": {
      "description": "Extract text from images using Tesseract OCR",
      "code_example": "import pytesseract\nfrom PIL import Image\n\n# Load image\nimage = Image.open('image.png')\n\n# OCR\ntext = pytesseract.image_to_string(image, lang='eng')\nprint(text)\n\n# With preprocessing\nfrom PIL import ImageEnhance\n\n# Enhance contrast\nenhancer = ImageEnhance.Contrast(image)\nenhanced = enhancer.enhance(2.0)\n\n# OCR enhanced image\ntext = pytesseract.image_to_string(enhanced, lang='eng')",
      "best_practices": [
        "Preprocess images for better OCR",
        "Enhance contrast, resize if needed",
        "Specify language",
        "Handle different image formats"
      ],
      "use_when": "Apply when implementing pytesseract ocr in integration context"
    },
    "easyocr_extraction": {
      "description": "Extract text using EasyOCR",
      "code_example": "import easyocr\n\n# Create reader\nreader = easyocr.Reader(['en'])  # English\n\n# Read text from image\nresult = reader.readtext('image.png')\n\n# Process results\nfor detection in result:\n    bbox, text, confidence = detection\n    print(f'Text: {text}, Confidence: {confidence:.2f}')",
      "best_practices": [
        "Good for multilingual text",
        "Returns bounding boxes",
        "Provides confidence scores",
        "Slower than Tesseract"
      ],
      "use_when": "Apply when implementing easyocr extraction in integration context"
    }
  },
  "chunking_strategies": {
    "recursive_character_chunking": {
      "description": "Split documents by characters with hierarchy",
      "code_example": "from langchain.text_splitter import RecursiveCharacterTextSplitter\n\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n    separators=['\\n\\n', '\\n', '. ', ' ', '']\n)\n\nchunks = splitter.split_text(document_text)\n\nfor i, chunk in enumerate(chunks):\n    print(f'Chunk {i+1}: {chunk[:200]}...')",
      "best_practices": [
        "Use for general text",
        "Set chunk_size 500-1500 tokens",
        "Use 10-20% overlap",
        "Order separators from most to least preferred"
      ],
      "use_when": "Apply when implementing recursive character chunking in integration context"
    },
    "semantic_chunking": {
      "description": "Chunk based on semantic similarity",
      "code_example": "from langchain_experimental.text_splitter import SemanticChunker\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n\nchunker = SemanticChunker(\n    embeddings,\n    breakpoint_threshold_type='percentile',\n    breakpoint_threshold_amount=95\n)\n\nchunks = chunker.split_text(document_text)",
      "best_practices": [
        "More expensive (requires embeddings)",
        "Better semantic coherence",
        "Chunks may vary in size",
        "Good for complex documents"
      ],
      "use_when": "Apply when implementing semantic chunking in integration context"
    },
    "title_based_chunking": {
      "description": "Chunk by document structure (titles, headings)",
      "code_example": "from unstructured.chunking.title import chunk_by_title\nfrom unstructured.partition.auto import partition\n\n# Partition document\n elements = partition('document.pdf')\n\n# Chunk by title\nchunks = chunk_by_title(\n    elements,\n    max_characters=1000,\n    combine_text_under_n_chars=200\n)\n\nfor chunk in chunks:\n    print(f'Title: {chunk.metadata.get(\"title\", \"N/A\")}')\n    print(f'Content: {chunk.text[:200]}...')",
      "best_practices": [
        "Preserves document structure",
        "Better for structured documents",
        "Maintains heading hierarchy",
        "Use for documents with clear structure"
      ],
      "use_when": "Apply when implementing title based chunking in integration context"
    },
    "sentence_chunking": {
      "description": "Implements sentence chunking for reliable, maintainable code. Use when the scenario requires this pattern.",
      "code_example": "from langchain.text_splitter import SentenceSplitter\n\nsplitter = SentenceSplitter(\n    chunk_size=1000,\n    chunk_overlap=200\n)\n\nchunks = splitter.split_text(document_text)",
      "best_practices": [
        "Good for natural language",
        "Preserves sentence boundaries",
        "Use for narrative text",
        "May split related sentences"
      ],
      "use_when": "Apply when implementing sentence chunking in integration context"
    },
    "token_based_chunking": {
      "description": "Chunk by tokens (for token-limited models)",
      "code_example": "from langchain.text_splitter import TokenTextSplitter\n\nsplitter = TokenTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n    encoding_name='cl100k_base'  # GPT tokenizer\n)\n\nchunks = splitter.split_text(document_text)",
      "best_practices": [
        "Use for token-limited models",
        "More accurate than character-based",
        "Specify correct encoding",
        "Good for LLM context windows"
      ],
      "use_when": "Apply when implementing token based chunking in integration context"
    }
  },
  "metadata_extraction": {
    "document_metadata": {
      "description": "Extract and preserve document metadata",
      "code_example": "from docling.document_converter import DocumentConverter\nfrom langchain.schema import Document\n\n# Convert with Docling\nconverter = DocumentConverter()\nresult = converter.convert('document.pdf')\n\n# Extract metadata\nmetadata = {\n    'source': 'document.pdf',\n    'title': result.document.metadata.get('title', ''),\n    'author': result.document.metadata.get('author', ''),\n    'pages': len(result.document.pages),\n    'sections': len(result.document.sections)\n}\n\n# Create LangChain documents with metadata\ndocuments = []\nfor section in result.document.sections:\n    doc = Document(\n        page_content=section.text,\n        metadata={\n            **metadata,\n            'section_title': section.title,\n            'section_index': section.index\n        }\n    )\n    documents.append(doc)",
      "best_practices": [
        "Extract source, title, author, date",
        "Preserve page numbers, section info",
        "Include processing metadata",
        "Use consistent metadata schema"
      ],
      "use_when": "Apply when implementing document metadata in integration context"
    },
    "chunk_metadata": {
      "description": "Add metadata to chunks",
      "code_example": "from langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.schema import Document\n\n# Split document\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200\n)\n\n# Create documents with metadata\nsource_doc = Document(\n    page_content=document_text,\n    metadata={\n        'source': 'document.pdf',\n        'page': 1,\n        'date': '2024-01-01'\n    }\n)\n\n# Split with metadata preservation\nchunks = splitter.split_documents([source_doc])\n\n# Metadata is preserved in chunks\nfor chunk in chunks:\n    print(f'Source: {chunk.metadata[\"source\"]}')\n    print(f'Content: {chunk.page_content[:200]}...')",
      "best_practices": [
        "Preserve source metadata in chunks",
        "Add chunk-specific metadata (chunk_index)",
        "Include page numbers when available",
        "Track chunk relationships"
      ],
      "use_when": "Apply when implementing chunk metadata in integration context"
    }
  },
  "anti_patterns": [
    {
      "name": "No structure preservation",
      "problem": "Using plain text extraction without preserving document structure (headings, sections, tables) leads to lost context, poor chunking, and reduced retrieval quality",
      "solution": "Use structured extraction tools (Docling, Unstructured.io) that preserve document hierarchy, sections, headings, and table structure"
    },
    {
      "name": "Ignoring table extraction",
      "problem": "Not extracting tables from documents causes loss of structured data, relationships, and important information contained in tabular format",
      "solution": "Enable table extraction with structure preservation (HTML format) in processing tools - use infer_table_structure=True in Unstructured or do_table_structure=True in Docling"
    },
    {
      "name": "No OCR for scanned documents",
      "problem": "Attempting native text extraction on scanned PDFs or images results in no text extracted, empty documents, or extraction failures",
      "solution": "Detect scanned documents (check text length after native extraction), enable OCR (do_ocr=True, strategy='hi_res') for scanned PDFs and images"
    },
    {
      "name": "Poor chunking without structure awareness",
      "problem": "Chunking documents without considering structure (headings, sections) leads to poor semantic coherence, split context, and reduced RAG quality",
      "solution": "Use semantic chunking (SemanticChunker) or title-based chunking (chunk_by_title) that respects document structure and maintains semantic coherence"
    },
    {
      "name": "Missing document metadata",
      "problem": "Not preserving document metadata (source, page, date, author) makes it impossible to trace sources, provide citations, or filter by document attributes",
      "solution": "Always extract and preserve metadata throughout processing pipeline - include source file, page numbers, dates, and any domain-specific attributes in chunk metadata"
    }
  ],
  "best_practices_summary": [
    "Use Docling or Unstructured for structured extraction",
    "Enable OCR for scanned documents",
    "Extract tables with structure preservation",
    "Preserve document metadata (source, page, date)",
    "Use semantic or title-based chunking when possible",
    "Set appropriate chunk size (500-1500 tokens)",
    "Use 10-20% overlap between chunks",
    "Handle different document formats appropriately",
    "Extract images when needed",
    "Track processing metadata for debugging"
  ],
  "patterns": {
    "structured_extraction_pipeline": {
      "description": "Use structured extraction tools that preserve document hierarchy, sections, headings, and tables",
      "use_when": "Processing documents for RAG systems where structure preservation improves retrieval and generation quality",
      "implementation": "Use Docling DocumentConverter or Unstructured partition functions with structure preservation enabled, access structured output (sections, tables, images)",
      "code_example": "Use Docling DocumentConverter or Unstructured partition functions with structure preservation enabled, access structured output (sections, tables, images)",
      "best_practices": [
        "Document the pattern usage and rationale in code comments for structured_extraction_pipeline",
        "Validate implementation against domain requirements before deployment"
      ]
    },
    "ocr_fallback_strategy": {
      "description": "Try native text extraction first, fallback to OCR if text is sparse or missing",
      "use_when": "Processing mixed PDF types (native text and scanned) where you want fast processing for text PDFs and OCR for scanned",
      "implementation": "Extract native text, check text length or quality, if below threshold convert pages to images and run OCR with appropriate DPI (300+)",
      "code_example": "Extract native text, check text length or quality, if below threshold convert pages to images and run OCR with appropriate DPI (300+)",
      "best_practices": [
        "Document the pattern usage and rationale in code comments for ocr_fallback_strategy",
        "Validate implementation against domain requirements before deployment"
      ]
    },
    "table_structure_preservation": {
      "description": "Extract tables with structure preservation (HTML format) rather than plain text to maintain relationships",
      "use_when": "Documents contain tables with important structured data that needs to be queried or displayed",
      "implementation": "Enable infer_table_structure=True in Unstructured or do_table_structure=True in Docling, extract tables as HTML or structured data format",
      "code_example": "Enable infer_table_structure=True in Unstructured or do_table_structure=True in Docling, extract tables as HTML or structured data format",
      "best_practices": [
        "Document the pattern usage and rationale in code comments for table_structure_preservation",
        "Validate implementation against domain requirements before deployment"
      ]
    },
    "title_based_chunking": {
      "description": "Chunk documents by titles/headings to preserve document structure and maintain semantic coherence",
      "use_when": "Documents have clear structure with headings and sections, need to preserve context for RAG",
      "implementation": "Use chunk_by_title from Unstructured or detect headings in Docling output, group content under headings, chunk with max_characters and overlap",
      "code_example": "Use chunk_by_title from Unstructured or detect headings in Docling output, group content under headings, chunk with max_characters and overlap",
      "best_practices": [
        "Document the pattern usage and rationale in code comments for title_based_chunking",
        "Validate implementation against domain requirements before deployment"
      ]
    },
    "metadata_preservation_chain": {
      "description": "Preserve document metadata (source, page, date) throughout processing pipeline for citation and filtering",
      "use_when": "Building RAG systems that need source attribution, filtering by document attributes, or citation generation",
      "implementation": "Extract metadata at document level, propagate to chunks during splitting, store in vector database metadata, include in RAG prompts for citation",
      "code_example": "Extract metadata at document level, propagate to chunks during splitting, store in vector database metadata, include in RAG prompts for citation",
      "best_practices": [
        "Document the pattern usage and rationale in code comments for metadata_preservation_chain",
        "Validate implementation against domain requirements before deployment"
      ]
    },
    "multi_format_processing": {
      "description": "Handle different document formats (PDF, Word, HTML, images) with format-specific extraction strategies",
      "use_when": "Processing diverse document types that require different extraction approaches for optimal results",
      "implementation": "Use format-specific partition functions (partition_pdf, partition_html, partition_image) or format_options in Docling with appropriate settings per format",
      "code_example": "Use format-specific partition functions (partition_pdf, partition_html, partition_image) or format_options in Docling with appropriate settings per format",
      "best_practices": [
        "Document the pattern usage and rationale in code comments for multi_format_processing",
        "Validate implementation against domain requirements before deployment"
      ]
    },
    "batch_processing_with_error_handling": {
      "description": "Process multiple documents in batch with per-document error handling to avoid pipeline failures",
      "use_when": "Processing large document collections where individual document failures shouldn't stop entire pipeline",
      "implementation": "Iterate through documents, wrap each in try-except, log errors per document, continue processing remaining documents, track success/failure status",
      "code_example": "Iterate through documents, wrap each in try-except, log errors per document, continue processing remaining documents, track success/failure status",
      "best_practices": [
        "Document the pattern usage and rationale in code comments for batch_processing_with_error_handling",
        "Validate implementation against domain requirements before deployment"
      ]
    },
    "image_and_figure_extraction": {
      "description": "Extract images and figures from documents for multimodal RAG systems",
      "use_when": "Documents contain images, charts, or figures that are relevant for retrieval and generation",
      "implementation": "Enable extract_images_in_pdf or extract_image_block_types, store image paths and captions in metadata, use for multimodal embeddings if needed",
      "code_example": "Enable extract_images_in_pdf or extract_image_block_types, store image paths and captions in metadata, use for multimodal embeddings if needed",
      "best_practices": [
        "Document the pattern usage and rationale in code comments for image_and_figure_extraction",
        "Validate implementation against domain requirements before deployment"
      ]
    }
  },
  "best_practices": [
    "Use structured extraction tools (Docling, Unstructured.io) that preserve document structure (sections, headings, tables) rather than plain text extraction",
    "Enable OCR for scanned PDFs and images - use hi_res strategy for complex layouts, ocr_only for simple text extraction",
    "Extract tables with structure preservation (HTML format) rather than plain text to maintain relationships and enable structured queries",
    "Preserve document metadata (source file, page numbers, author, date) throughout processing pipeline for citation and traceability",
    "Use semantic or title-based chunking when possible to maintain document structure and improve retrieval quality in RAG systems",
    "Set chunk size to 500-1500 tokens based on your embedding model's context window, with 10-20% overlap for context preservation",
    "Handle different document formats appropriately - use format-specific options (PDF pipeline options, Word extraction settings) for optimal results",
    "Extract images and figures when needed for multimodal RAG systems, storing image paths and captions in metadata"
  ],
  "related_skills": [
    "none"
  ],
  "related_knowledge": [
    "best-practices.json"
  ]
}