---
## Overview

description: ML model evaluation workflow covering metrics selection, model comparison, and reporting. Supports classification, re...
---

# Model Evaluation

ML model evaluation workflow covering metrics selection, model comparison, and reporting. Supports classification, regression, and LLM evaluation with structured reporting.

**Version:** 1.0.0
**Created:** 2026-02-10
**Applies To:** ml-models, llm-applications

## Trigger Conditions

This workflow is activated when:

- Model evaluation requested
- Model comparison needed
- Pre-deployment validation
- Benchmarking new models

**Trigger Examples:**
- "Evaluate the trained model"
- "Compare model A vs B"
- "Run evaluation and generate report"
- "Benchmark the new fine-tuned model"

## Steps

### Define Metrics

### Prepare Dataset

### Execute Evaluation

### Compare Models (if applicable)

### Analyze Failure Modes

### Statistical Significance

### Generate Report

### Share and Archive


## Decision Points

- Is the requirement clear?
- Are the tests passing?


## Example Session

User: Run the workflow
Agent: Initiating workflow steps...
