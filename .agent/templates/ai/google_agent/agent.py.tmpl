"""
{{AGENT_NAME}} - Google Generative AI Agent Implementation

Purpose: {{AGENT_PURPOSE}}
Stakeholders: {{PRIMARY_STAKEHOLDERS}}

Axiom Alignment:
- A1 (Verifiability): All outputs include reasoning traces
- A2 (User Primacy): Confirms before consequential actions
- A3 (Transparency): Decisions are explainable
- A4 (Non-Harm): Refuses harmful requests
"""

import os
import logging
from typing import Dict, Any, List, Optional, Union
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from pydantic import BaseModel, Field

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Configuration ---
# Ensure GOOGLE_API_KEY is set in your environment
if not os.environ.get("GOOGLE_API_KEY"):
    logger.warning("GOOGLE_API_KEY not set. Agent may fail to initialize.")

class AgentState(BaseModel):
    """Current state of the agent conversation."""
    history: List[Dict[str, Any]] = Field(default_factory=list)
    context: Optional[str] = None

class {{AGENT_CLASS_NAME}}Output(BaseModel):
    """
    Structured output for {{AGENT_NAME}}.
    Using Pydantic for schema validation ensures verifiability (A1).
    """
    reasoning: str = Field(description="Step-by-step reasoning for the response")
    response: str = Field(description="The main response to the user")
    confidence: float = Field(ge=0, le=1, description="Confidence level (0-1)")
    requires_confirmation: bool = Field(
        default=False, 
        description="Whether this action requires user confirmation (A2)"
    )
    warnings: List[str] = Field(
        default_factory=list,
        description="Any warnings or concerns (A4)"
    )

class {{AGENT_CLASS_NAME}}:
    """
    {{AGENT_NAME}} - {{AGENT_DESCRIPTION}}
    
    Powered by Google's Gemini models.
    """
    
    MODEL_NAME = "{{LLM_MODEL}}" # e.g., "gemini-1.5-pro-latest"
    TEMPERATURE = {{TEMPERATURE}}
    
    def __init__(self, model_name: Optional[str] = None, tools: Optional[List] = None):
        """
        Initialize the {{AGENT_NAME}} agent.
        
        Args:
            model_name: Gemini model to use (default: {{LLM_MODEL}})
            tools: List of tools (functions) available to the agent
        """
        self.model_name = model_name or self.MODEL_NAME
        self.tools = tools or []
        
        # Configure safety settings (A4 - Non-Harm)
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
        }
        
        self._initialize_model()
        logger.info(f"Initialized {{AGENT_NAME}} with model {self.model_name}")

    def _initialize_model(self):
        """Initialize the Gemini model with system instruction and tools."""
        system_instruction = self._create_system_instruction()
        
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            safety_settings=self.safety_settings,
            system_instruction=system_instruction,
            tools=self.tools,
            generation_config=genai.GenerationConfig(
                temperature=self.TEMPERATURE,
                response_mime_type="application/json",
                response_schema={{AGENT_CLASS_NAME}}Output
            )
        )
        # Start a chat session
        self.chat = self.model.start_chat(history=[])

    def _create_system_instruction(self) -> str:
        """Create system prompt with axioms."""
        return """{{SYSTEM_PROMPT}}

## Core Axioms (You MUST follow these)
1. VERIFIABILITY (A1): Explain your reasoning.
2. USER PRIMACY (A2): Prioritize user intent. Confirm consequential actions.
3. TRANSPARENCY (A3): Be clear about your actions.
4. NON-HARM (A4): Refuse harmful requests.
5. CONSISTENCY (A5): Align with these principles.

## Purpose
{{AGENT_PURPOSE}}

## Output Format
You must respond with a JSON object matching the {{AGENT_CLASS_NAME}}Output schema:
- reasoning: str
- response: str
- confidence: float (0.0 to 1.0)
- requires_confirmation: bool
- warnings: List[str]
"""

    def invoke(self, input_text: str, context: Optional[str] = None) -> {{AGENT_CLASS_NAME}}Output:
        """
        Invoke the agent with user input.
        
        Args:
            input_text: User's input/question
            context: Optional additional context
            
        Returns:
            Structured output object
        """
        logger.info(f"Processing input: {input_text[:100]}...")
        
        message = input_text
        if context:
            message = f"Context: {context}\n\nUser Input: {input_text}"
            
        try:
            response = self.chat.send_message(message)
            
            # Since we requested JSON response, we can parse it directly
            # Note: The SDK might return a text string that is JSON
            try:
                import json
                cleaned_text = response.text.strip()
                if cleaned_text.startswith("```json"):
                    cleaned_text = cleaned_text[7:-3]
                data = json.loads(cleaned_text)
                result = {{AGENT_CLASS_NAME}}Output(**data)
            except Exception as parse_error:
                logger.error(f"Failed to parse JSON response: {parse_error}")
                # Fallback extraction if strict JSON fails
                result = {{AGENT_CLASS_NAME}}Output(
                    reasoning="Failed to parse structured response.",
                    response=response.text,
                    confidence=0.5,
                    requires_confirmation=True,
                    warnings=["Could not validate output structure"]
                )

            # Log for transparency (A3)
            logger.info(f"Response generated with confidence: {result.confidence}")
            if result.requires_confirmation:
                logger.info("Action requires user confirmation (A2)")
                
            return result
            
        except Exception as e:
            logger.error(f"Error during invocation: {e}")
            return {{AGENT_CLASS_NAME}}Output(
                reasoning="Internal error",
                response=f"I encountered an error: {str(e)}",
                confidence=0.0,
                requires_confirmation=False,
                warnings=["Error occurred during processing"]
            )

# Example usage
if __name__ == "__main__":
    # Ensure API key is set
    if not os.environ.get("GOOGLE_API_KEY"):
        print("Please set GOOGLE_API_KEY environment variable.")
        exit(1)

    agent = {{AGENT_CLASS_NAME}}()
    result = agent.invoke("{{EXAMPLE_INPUT}}")
    
    print(f"Reasoning: {result.reasoning}")
    print(f"Response: {result.response}")
