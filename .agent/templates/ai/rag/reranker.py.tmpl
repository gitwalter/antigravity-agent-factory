"""
{{RERANKER_NAME}} - Cross-Encoder Reranking

Purpose: {{RERANKER_PURPOSE}}
Author: {{AUTHOR}}
Date: {{DATE}}

Axiom Alignment:
- A1 (Verifiability): Reranking scores are transparent and traceable
- A3 (Transparency): Reranking process improves precision with explainable scores
"""

from typing import List, Dict, Any, Optional, Tuple
from langchain_core.documents import Document
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import BaseDocumentCompressor
from langchain_cohere import CohereRerank
from langchain_openai import ChatOpenAI
from sentence_transformers import CrossEncoder
from pydantic import BaseModel, Field
import logging
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RerankedDocument(BaseModel):
    """Document with reranking score."""
    document: Document = Field(description="The document")
    score: float = Field(description="Reranking relevance score")
    original_rank: int = Field(description="Original rank before reranking")


class RerankingResult(BaseModel):
    """Result from reranking operation."""
    documents: List[Document] = Field(description="Reranked documents")
    scores: List[float] = Field(description="Reranking scores")
    metadata: Dict[str, Any] = Field(
        default_factory=dict,
        description="Reranking metadata",
    )


class CrossEncoderReranker(BaseDocumentCompressor):
    """
    Cross-encoder reranker using sentence-transformers.

    Cross-encoders provide better accuracy than bi-encoders for reranking
    by jointly encoding query-document pairs.
    """

    def __init__(
        self,
        model_name: str = "{{CROSS_ENCODER_MODEL}}",
        top_n: int = {{TOP_N}},
        device: Optional[str] = None,
    ):
        """
        Initialize cross-encoder reranker.

        Args:
            model_name: Name of the cross-encoder model
            top_n: Number of top documents to return
            device: Device to run on ("cpu", "cuda", or None for auto)
        """
        super().__init__()
        self.model_name = model_name
        self.top_n = top_n
        self.device = device

        logger.info(f"Loading cross-encoder model: {model_name}")
        self.model = CrossEncoder(model_name, device=device)
        logger.info("Cross-encoder model loaded")

    def compress_documents(
        self,
        documents: List[Document],
        query: str,
    ) -> List[Document]:
        """
        Rerank documents using cross-encoder.

        Args:
            documents: Documents to rerank
            query: Query string

        Returns:
            Reranked documents
        """
        if not documents:
            return []

        logger.info(f"Reranking {len(documents)} documents for query: {query[:50]}...")

        # Create query-document pairs
        pairs = [[query, doc.page_content] for doc in documents]

        # Get reranking scores
        scores = self.model.predict(pairs)

        # Sort by score (descending)
        scored_docs = list(zip(documents, scores))
        scored_docs.sort(key=lambda x: x[1], reverse=True)

        # Return top N
        reranked_docs = [doc for doc, _ in scored_docs[: self.top_n]]

        logger.info(f"Reranked to top {len(reranked_docs)} documents")
        return reranked_docs


class {{RERANKER_CLASS_NAME}}:
    """
    {{RERANKER_NAME}} - Cross-Encoder Reranking System

    Reranks retrieval results using cross-encoder models for improved precision.
    Supports multiple reranking backends (Cohere API, local cross-encoders, LLM-based).

    Example:
        >>> reranker = {{RERANKER_CLASS_NAME}}(
        ...     reranker_type="cross_encoder",
        ...     top_n=5
        ... )
        >>> reranked = reranker.rerank(query, documents)
        >>> print(f"Reranked to {len(reranked.documents)} documents")
    """

    def __init__(
        self,
        reranker_type: str = "{{RERANKER_TYPE}}",  # "cohere", "cross_encoder", "llm"
        top_n: int = {{TOP_N}},
        model_name: Optional[str] = None,
        cohere_api_key: Optional[str] = None,
        llm_model: str = "{{LLM_MODEL}}",
        device: Optional[str] = None,
    ):
        """
        Initialize reranker.

        Args:
            reranker_type: Type of reranker ("cohere", "cross_encoder", "llm")
            top_n: Number of top documents to return after reranking
            model_name: Model name (for cross_encoder or llm)
            cohere_api_key: Cohere API key (for cohere reranker)
            llm_model: LLM model name (for llm reranker)
            device: Device for cross-encoder ("cpu", "cuda", or None)
        """
        self.reranker_type = reranker_type
        self.top_n = top_n
        self.device = device

        # Initialize reranker based on type
        self.reranker: Optional[Any] = None

        if reranker_type == "cohere":
            if not cohere_api_key:
                raise ValueError("cohere_api_key required for Cohere reranker")
            logger.info("Initializing Cohere reranker...")
            self.reranker = CohereRerank(
                top_n=top_n,
                model="rerank-english-v3.0",  # or "rerank-multilingual-v3.0"
                cohere_api_key=cohere_api_key,
            )
        elif reranker_type == "cross_encoder":
            model = model_name or "{{CROSS_ENCODER_MODEL}}"
            logger.info(f"Initializing cross-encoder reranker with model: {model}")
            self.reranker = CrossEncoderReranker(
                model_name=model,
                top_n=top_n,
                device=device,
            )
        elif reranker_type == "llm":
            logger.info(f"Initializing LLM reranker with model: {llm_model}")
            from langchain.retrievers.document_compressors import LLMRerank

            llm = ChatOpenAI(model=llm_model, temperature=0)
            self.reranker = LLMRerank.from_llm(llm=llm, top_n=top_n)
        else:
            raise ValueError(
                f"Unknown reranker type: {reranker_type}. "
                "Choose from: 'cohere', 'cross_encoder', 'llm'"
            )

        logger.info(
            f"Initialized {{RERANKER_NAME}} with {reranker_type} reranker, top_n={top_n}"
        )

    def rerank(
        self,
        query: str,
        documents: List[Document],
    ) -> RerankingResult:
        """
        Rerank documents for a query.

        Args:
            query: Query string
            documents: Documents to rerank

        Returns:
            RerankingResult with reranked documents and scores

        Example:
            >>> result = reranker.rerank("machine learning", documents)
            >>> for doc, score in zip(result.documents, result.scores):
            ...     print(f"Score: {score:.3f} - {doc.page_content[:50]}")
        """
        if not documents:
            return RerankingResult(
                documents=[],
                scores=[],
                metadata={"query": query, "reranker_type": self.reranker_type},
            )

        logger.info(f"Reranking {len(documents)} documents for query: {query[:50]}...")

        try:
            # Use the reranker
            if self.reranker_type == "cross_encoder":
                # CrossEncoderReranker returns documents directly
                reranked_docs = self.reranker.compress_documents(documents, query)

                # Extract scores by recomputing (or store during compression)
                pairs = [[query, doc.page_content] for doc in documents]
                all_scores = self.reranker.model.predict(pairs)

                # Map scores to reranked documents
                doc_to_score = {
                    doc.page_content: score
                    for doc, score in zip(documents, all_scores)
                }
                scores = [
                    doc_to_score.get(doc.page_content, 0.0) for doc in reranked_docs
                ]
            else:
                # Cohere or LLM reranker
                reranked_docs = self.reranker.compress_documents(documents, query)

                # Extract scores from metadata if available
                scores = []
                for doc in reranked_docs:
                    score = doc.metadata.get("relevance_score", 1.0)
                    scores.append(score)

            result = RerankingResult(
                documents=reranked_docs,
                scores=scores,
                metadata={
                    "query": query,
                    "reranker_type": self.reranker_type,
                    "original_count": len(documents),
                    "reranked_count": len(reranked_docs),
                },
            )

            logger.info(
                f"Reranked {len(documents)} documents to top {len(reranked_docs)}"
            )
            return result

        except Exception as e:
            logger.error(f"Error during reranking: {e}")
            # Return original documents on error
            return RerankingResult(
                documents=documents[: self.top_n],
                scores=[1.0] * min(len(documents), self.top_n),
                metadata={
                    "query": query,
                    "error": str(e),
                    "reranker_type": self.reranker_type,
                },
            )

    async def arerank(
        self,
        query: str,
        documents: List[Document],
    ) -> RerankingResult:
        """Async version of rerank."""
        if not documents:
            return RerankingResult(
                documents=[],
                scores=[],
                metadata={"query": query, "reranker_type": self.reranker_type},
            )

        logger.info(f"Async reranking {len(documents)} documents...")

        try:
            if hasattr(self.reranker, "acompress_documents"):
                reranked_docs = await self.reranker.acompress_documents(
                    documents, query
                )
            else:
                # Fallback to sync
                reranked_docs = self.reranker.compress_documents(documents, query)

            # Extract scores
            scores = []
            for doc in reranked_docs:
                score = doc.metadata.get("relevance_score", 1.0)
                scores.append(score)

            result = RerankingResult(
                documents=reranked_docs,
                scores=scores,
                metadata={
                    "query": query,
                    "reranker_type": self.reranker_type,
                    "original_count": len(documents),
                    "reranked_count": len(reranked_docs),
                },
            )

            return result

        except Exception as e:
            logger.error(f"Error during async reranking: {e}")
            return RerankingResult(
                documents=documents[: self.top_n],
                scores=[1.0] * min(len(documents), self.top_n),
                metadata={"error": str(e)},
            )

    def create_compression_retriever(
        self,
        base_retriever: Any,
    ) -> ContextualCompressionRetriever:
        """
        Create a compression retriever that automatically reranks.

        Args:
            base_retriever: Base retriever to wrap

        Returns:
            ContextualCompressionRetriever with reranking

        Example:
            >>> compression_retriever = reranker.create_compression_retriever(base_retriever)
            >>> docs = compression_retriever.invoke("query")
        """
        if not self.reranker:
            raise ValueError("Reranker not initialized")

        logger.info("Creating compression retriever with reranking...")

        return ContextualCompressionRetriever(
            base_compressor=self.reranker,
            base_retriever=base_retriever,
        )

    def rerank_with_metadata(
        self,
        query: str,
        documents: List[Document],
        preserve_original_rank: bool = True,
    ) -> List[RerankedDocument]:
        """
        Rerank documents with detailed metadata.

        Args:
            query: Query string
            documents: Documents to rerank
            preserve_original_rank: Whether to include original rank

        Returns:
            List of RerankedDocument with scores and ranks

        Example:
            >>> reranked = reranker.rerank_with_metadata("query", documents)
            >>> for item in reranked:
            ...     print(f"Rank {item.original_rank} -> Score {item.score:.3f}")
        """
        result = self.rerank(query, documents)

        reranked_items = []
        for i, (doc, score) in enumerate(zip(result.documents, result.scores)):
            # Find original rank
            original_rank = i
            if preserve_original_rank:
                try:
                    original_rank = documents.index(doc)
                except ValueError:
                    original_rank = i

            reranked_items.append(
                RerankedDocument(
                    document=doc,
                    score=score,
                    original_rank=original_rank,
                )
            )

        return reranked_items


# Example usage
if __name__ == "__main__":
    from langchain_core.documents import Document

    # Create sample documents
    documents = [
        Document(
            page_content="Machine learning algorithms learn from data.",
            metadata={"source": "doc1"},
        ),
        Document(
            page_content="Deep learning is a subset of machine learning.",
            metadata={"source": "doc2"},
        ),
        Document(
            page_content="Neural networks are used in deep learning.",
            metadata={"source": "doc3"},
        ),
        Document(
            page_content="Natural language processing helps computers understand text.",
            metadata={"source": "doc4"},
        ),
        Document(
            page_content="Computer vision enables machines to interpret images.",
            metadata={"source": "doc5"},
        ),
    ]

    # Create reranker
    reranker = {{RERANKER_CLASS_NAME}}(
        reranker_type="cross_encoder",
        top_n=3,
        model_name="{{CROSS_ENCODER_MODEL}}",
    )

    # Rerank documents
    query = "{{EXAMPLE_QUERY}}"
    result = reranker.rerank(query, documents)

    print(f"Reranked {len(documents)} documents to top {len(result.documents)}:")
    print(f"\nQuery: {query}\n")
    for i, (doc, score) in enumerate(zip(result.documents, result.scores)):
        print(f"{i+1}. Score: {score:.4f}")
        print(f"   Content: {doc.page_content[:80]}...")
        print(f"   Source: {doc.metadata.get('source', 'unknown')}\n")

    # Rerank with metadata
    reranked_with_meta = reranker.rerank_with_metadata(query, documents)
    print("\nReranked with metadata:")
    for item in reranked_with_meta:
        print(
            f"  Original rank {item.original_rank} -> "
            f"Score {item.score:.4f}: {item.document.page_content[:50]}..."
        )
