"""
{{CONFIG_NAME}} - PEFT Configuration

Purpose: {{CONFIG_PURPOSE}}
Author: {{AUTHOR}}
Date: {{DATE}}

Axiom Alignment:
- A1 (Verifiability): Configuration is explicit and reproducible
- A3 (Transparency): Model adaptation strategy is clear
"""

from typing import Optional, List, Dict, Any, Union
from pathlib import Path
from peft import (
    LoraConfig,
    PromptTuningConfig,
    PromptTuningInit,
    TaskType,
    PeftType,
    get_peft_model,
    PeftModel,
)
from pydantic import BaseModel, Field
import json
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LoRAConfig(BaseModel):
    """LoRA (Low-Rank Adaptation) configuration."""
    r: int = Field(default={{LORA_R}}, description="LoRA rank")
    lora_alpha: int = Field(default={{LORA_ALPHA}}, description="LoRA alpha scaling")
    target_modules: List[str] = Field(
        default={{TARGET_MODULES}},
        description="Target modules for LoRA"
    )
    lora_dropout: float = Field(default={{LORA_DROPOUT}}, description="LoRA dropout")
    bias: str = Field(default="none", description="Bias type: none, all, lora_only")
    task_type: str = Field(default="CAUSAL_LM", description="Task type")
    inference_mode: bool = Field(default=False, description="Inference mode")


class PromptTuningConfigModel(BaseModel):
    """Prompt Tuning configuration."""
    num_virtual_tokens: int = Field(
        default={{NUM_VIRTUAL_TOKENS}},
        description="Number of virtual tokens"
    )
    task_type: str = Field(default="CAUSAL_LM", description="Task type")
    prompt_tuning_init: str = Field(
        default="RANDOM",
        description="Prompt initialization: RANDOM, TEXT"
    )
    prompt_tuning_init_text: Optional[str] = Field(
        default=None,
        description="Initial text for TEXT initialization"
    )
    tokenizer_name_or_path: Optional[str] = Field(
        default=None,
        description="Tokenizer for TEXT initialization"
    )


class {{CONFIG_CLASS_NAME}}:
    """
    {{CONFIG_NAME}} - PEFT Configuration Manager

    Manages Parameter-Efficient Fine-Tuning (PEFT) configurations including
    LoRA, Prompt Tuning, and other PEFT methods. Provides utilities for
    creating, saving, and loading PEFT configurations.

    Example:
        >>> config_manager = {{CONFIG_CLASS_NAME}}()
        >>> lora_config = config_manager.create_lora_config(
        ...     r=16,
        ...     target_modules=["q_proj", "v_proj"]
        ... )
        >>> config_manager.save_config(lora_config, "configs/lora.json")
    """

    def __init__(self):
        """Initialize PEFT configuration manager."""
        self.configs: Dict[str, Any] = {}

    def create_lora_config(
        self,
        r: int = {{LORA_R}},
        lora_alpha: int = {{LORA_ALPHA}},
        target_modules: Optional[List[str]] = None,
        lora_dropout: float = {{LORA_DROPOUT}},
        bias: str = "none",
        task_type: TaskType = TaskType.CAUSAL_LM,
        inference_mode: bool = False,
    ) -> LoraConfig:
        """
        Create LoRA configuration.

        Args:
            r: LoRA rank (lower = fewer parameters)
            lora_alpha: LoRA alpha scaling parameter
            target_modules: Modules to apply LoRA to
            lora_dropout: LoRA dropout rate
            bias: Bias type ("none", "all", "lora_only")
            task_type: Task type (CAUSAL_LM, SEQ_2_SEQ_LM, etc.)
            inference_mode: Whether in inference mode

        Returns:
            LoraConfig object

        Example:
            >>> config = config_manager.create_lora_config(
            ...     r=16,
            ...     lora_alpha=32,
            ...     target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
            ... )
        """
        if target_modules is None:
            target_modules = {{TARGET_MODULES}}

        config = LoraConfig(
            r=r,
            lora_alpha=lora_alpha,
            target_modules=target_modules,
            lora_dropout=lora_dropout,
            bias=bias,
            task_type=task_type,
            inference_mode=inference_mode,
        )

        logger.info(
            f"Created LoRA config: r={r}, alpha={lora_alpha}, "
            f"target_modules={target_modules}"
        )

        return config

    def create_prompt_tuning_config(
        self,
        num_virtual_tokens: int = {{NUM_VIRTUAL_TOKENS}},
        task_type: TaskType = TaskType.CAUSAL_LM,
        prompt_tuning_init: PromptTuningInit = PromptTuningInit.RANDOM,
        prompt_tuning_init_text: Optional[str] = None,
        tokenizer_name_or_path: Optional[str] = None,
    ) -> PromptTuningConfig:
        """
        Create Prompt Tuning configuration.

        Args:
            num_virtual_tokens: Number of virtual prompt tokens
            task_type: Task type
            prompt_tuning_init: Initialization method (RANDOM or TEXT)
            prompt_tuning_init_text: Initial text for TEXT initialization
            tokenizer_name_or_path: Tokenizer path for TEXT initialization

        Returns:
            PromptTuningConfig object

        Example:
            >>> config = config_manager.create_prompt_tuning_config(
            ...     num_virtual_tokens=20,
            ...     prompt_tuning_init=PromptTuningInit.TEXT,
            ...     prompt_tuning_init_text="Classify the following text:"
            ... )
        """
        config_kwargs = {
            "num_virtual_tokens": num_virtual_tokens,
            "task_type": task_type,
            "prompt_tuning_init": prompt_tuning_init,
        }

        if prompt_tuning_init == PromptTuningInit.TEXT:
            if prompt_tuning_init_text is None:
                raise ValueError(
                    "prompt_tuning_init_text required for TEXT initialization"
                )
            if tokenizer_name_or_path is None:
                raise ValueError(
                    "tokenizer_name_or_path required for TEXT initialization"
                )
            config_kwargs["prompt_tuning_init_text"] = prompt_tuning_init_text
            config_kwargs["tokenizer_name_or_path"] = tokenizer_name_or_path

        config = PromptTuningConfig(**config_kwargs)

        logger.info(
            f"Created Prompt Tuning config: num_virtual_tokens={num_virtual_tokens}"
        )

        return config

    def get_default_lora_config_for_model(
        self,
        model_name: str,
        r: int = {{LORA_R}},
        lora_alpha: Optional[int] = None,
    ) -> LoraConfig:
        """
        Get default LoRA config for a specific model architecture.

        Args:
            model_name: Model name or architecture identifier
            r: LoRA rank
            lora_alpha: LoRA alpha (defaults to 2*r)

        Returns:
            LoraConfig with model-specific defaults

        Example:
            >>> config = config_manager.get_default_lora_config_for_model(
            ...     "llama",
            ...     r=16
            ... )
        """
        if lora_alpha is None:
            lora_alpha = 2 * r

        # Model-specific target modules
        model_targets = {
            "llama": ["q_proj", "v_proj", "k_proj", "o_proj"],
            "mistral": ["q_proj", "v_proj", "k_proj", "o_proj"],
            "gpt2": ["c_attn", "c_proj"],
            "gpt-neo": ["q_proj", "v_proj", "k_proj", "out_proj"],
            "opt": ["q_proj", "v_proj", "k_proj", "out_proj"],
            "t5": ["q", "v", "k", "o"],
            "bert": ["query", "value"],
        }

        # Find matching model
        target_modules = None
        for model_key, modules in model_targets.items():
            if model_key.lower() in model_name.lower():
                target_modules = modules
                break

        if target_modules is None:
            # Default fallback
            target_modules = {{TARGET_MODULES}}
            logger.warning(
                f"Unknown model architecture '{model_name}', "
                f"using default target_modules: {target_modules}"
            )

        return self.create_lora_config(
            r=r,
            lora_alpha=lora_alpha,
            target_modules=target_modules,
        )

    def save_config(
        self,
        config: Union[LoraConfig, PromptTuningConfig],
        file_path: str,
    ) -> None:
        """
        Save PEFT configuration to JSON file.

        Args:
            config: PEFT configuration object
            file_path: Path to save configuration

        Example:
            >>> config_manager.save_config(lora_config, "configs/my_lora.json")
        """
        file_path = Path(file_path)
        file_path.parent.mkdir(parents=True, exist_ok=True)

        # Convert config to dict
        config_dict = config.to_dict()

        # Save to JSON
        with open(file_path, "w") as f:
            json.dump(config_dict, f, indent=2)

        logger.info(f"Saved PEFT config to {file_path}")

    def load_config(
        self,
        file_path: str,
        config_type: str = "lora",
    ) -> Union[LoraConfig, PromptTuningConfig]:
        """
        Load PEFT configuration from JSON file.

        Args:
            file_path: Path to configuration file
            config_type: Type of config ("lora" or "prompt_tuning")

        Returns:
            PEFT configuration object

        Example:
            >>> config = config_manager.load_config("configs/my_lora.json")
        """
        file_path = Path(file_path)

        if not file_path.exists():
            raise FileNotFoundError(f"Config file not found: {file_path}")

        # Load from JSON
        with open(file_path, "r") as f:
            config_dict = json.load(f)

        # Create config object
        if config_type == "lora":
            config = LoraConfig.from_dict(config_dict)
        elif config_type == "prompt_tuning":
            config = PromptTuningConfig.from_dict(config_dict)
        else:
            raise ValueError(f"Unknown config type: {config_type}")

        logger.info(f"Loaded {config_type} config from {file_path}")
        return config

    def print_config_summary(
        self,
        config: Union[LoraConfig, PromptTuningConfig],
    ) -> None:
        """
        Print summary of PEFT configuration.

        Args:
            config: PEFT configuration object

        Example:
            >>> config_manager.print_config_summary(lora_config)
        """
        print("\n" + "=" * 50)
        print("PEFT Configuration Summary")
        print("=" * 50)

        if isinstance(config, LoraConfig):
            print(f"Type: LoRA")
            print(f"Rank (r): {config.r}")
            print(f"Alpha: {config.lora_alpha}")
            print(f"Dropout: {config.lora_dropout}")
            print(f"Target Modules: {config.target_modules}")
            print(f"Bias: {config.bias}")
            print(f"Task Type: {config.task_type}")

            # Calculate parameter reduction
            if config.target_modules:
                print(f"\nParameter Efficiency:")
                print(f"  - Only {len(config.target_modules)} module types adapted")
                print(f"  - Rank {config.r} reduces parameters significantly")

        elif isinstance(config, PromptTuningConfig):
            print(f"Type: Prompt Tuning")
            print(f"Virtual Tokens: {config.num_virtual_tokens}")
            print(f"Task Type: {config.task_type}")
            print(f"Init Method: {config.prompt_tuning_init}")

            print(f"\nParameter Efficiency:")
            print(f"  - Only {config.num_virtual_tokens} virtual tokens trained")
            print(f"  - Minimal parameter overhead")

        print("=" * 50 + "\n")


# Example usage
if __name__ == "__main__":
    # Initialize config manager
    config_manager = {{CONFIG_CLASS_NAME}}()

    # Create LoRA config
    lora_config = config_manager.create_lora_config(
        r={{LORA_R}},
        lora_alpha={{LORA_ALPHA}},
        target_modules={{TARGET_MODULES}},
    )

    # Print summary
    config_manager.print_config_summary(lora_config)

    # Save config
    config_manager.save_config(lora_config, "{{CONFIG_OUTPUT_PATH}}")

    # Load config
    loaded_config = config_manager.load_config(
        "{{CONFIG_OUTPUT_PATH}}",
        config_type="lora"
    )

    # Get model-specific config
    model_config = config_manager.get_default_lora_config_for_model(
        "{{MODEL_NAME}}",
        r={{LORA_R}}
    )
    config_manager.print_config_summary(model_config)
